{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "# from sklearn.cross_validation import KFold, cross_val_score\n",
    "# Cross Validation, use the method in XGBoost if needed. \n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        Unnamed: 0   age  weight  height     art_mbp     art_sbp         bt  \\\n",
       "0               3  50.0    66.0   157.0  100.826720  137.244265  29.656043   \n",
       "1               4  60.0    62.0   154.0  100.773779  138.601562  28.462637   \n",
       "2               5  35.0    50.0   160.0   98.084871  131.646617  29.201952   \n",
       "3               6  20.0    62.0   179.0   92.702290  140.826772  35.800000   \n",
       "4               7  60.0    52.0   152.0  100.773779  138.601562  28.462637   \n",
       "...           ...   ...     ...     ...         ...         ...        ...   \n",
       "74778       87838  80.0    61.0   171.0  106.000000  172.000000  27.672313   \n",
       "74779       87839  55.0    51.0   162.0  102.797362  139.350856  29.258995   \n",
       "74780       87840  80.0    60.0   160.0   99.704409  146.300403  27.672313   \n",
       "74781       87841  30.0    72.0   176.0  134.000000  178.000000  29.013889   \n",
       "74782       87842  45.0    58.0   158.0   98.192708  134.999118  30.278016   \n",
       "\n",
       "            cvp          hr        pip  ...  category_id_0WB  category_id_0WJ  \\\n",
       "0      2.457447   78.792763   4.000000  ...              0.0              0.0   \n",
       "1      0.603448   62.000000   5.000000  ...              0.0              0.0   \n",
       "2      7.653846   82.000000  13.546358  ...              0.0              0.0   \n",
       "3      0.272727   94.000000  12.820417  ...              0.0              0.0   \n",
       "4      0.603448   68.000000   4.000000  ...              0.0              0.0   \n",
       "...         ...         ...        ...  ...              ...              ...   \n",
       "74778  1.520000   51.000000   3.000000  ...              0.0              0.0   \n",
       "74779  0.581081   98.000000   6.000000  ...              0.0              0.0   \n",
       "74780  1.520000   49.000000   8.000000  ...              0.0              0.0   \n",
       "74781  7.400000  110.000000   9.000000  ...              0.0              0.0   \n",
       "74782  7.307692   69.500000  15.000000  ...              0.0              0.0   \n",
       "\n",
       "       category_id_0Y6  category_id_0YH  category_id_10D  asa_2.0  asa_3.0  \\\n",
       "0                  0.0              0.0              0.0      0.0      0.0   \n",
       "1                  0.0              0.0              0.0      0.0      0.0   \n",
       "2                  0.0              0.0              0.0      1.0      0.0   \n",
       "3                  0.0              0.0              0.0      1.0      0.0   \n",
       "4                  0.0              0.0              0.0      0.0      0.0   \n",
       "...                ...              ...              ...      ...      ...   \n",
       "74778              0.0              0.0              0.0      0.0      1.0   \n",
       "74779              0.0              0.0              0.0      1.0      0.0   \n",
       "74780              0.0              0.0              0.0      1.0      0.0   \n",
       "74781              0.0              0.0              0.0      1.0      0.0   \n",
       "74782              0.0              0.0              0.0      0.0      0.0   \n",
       "\n",
       "       asa_4.0  asa_5.0  asa_6.0  \n",
       "0          0.0      0.0      0.0  \n",
       "1          0.0      0.0      0.0  \n",
       "2          0.0      0.0      0.0  \n",
       "3          0.0      0.0      0.0  \n",
       "4          0.0      0.0      0.0  \n",
       "...        ...      ...      ...  \n",
       "74778      0.0      0.0      0.0  \n",
       "74779      0.0      0.0      0.0  \n",
       "74780      0.0      0.0      0.0  \n",
       "74781      0.0      0.0      0.0  \n",
       "74782      1.0      0.0      0.0  \n",
       "\n",
       "[74783 rows x 170 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./_data/1hot_encoded.csv')\n",
    "df.shape\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the X and y DataFrames\n",
    "\n",
    "  * create y\n",
    "  * create X (complete with all the features)\n",
    "  * drop the features we identified as not meeting impact threshold. \n",
    "  * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asa_3.0</th>\n",
       "      <th>asa_2.0</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>anesth_duration</th>\n",
       "      <th>or_duration</th>\n",
       "      <th>icu_visit</th>\n",
       "      <th>department_OT</th>\n",
       "      <th>antype_MAC</th>\n",
       "      <th>...</th>\n",
       "      <th>category_id_09Q</th>\n",
       "      <th>category_id_08R</th>\n",
       "      <th>category_id_0DB</th>\n",
       "      <th>category_id_0QS</th>\n",
       "      <th>category_id_0DT</th>\n",
       "      <th>category_id_0W3</th>\n",
       "      <th>category_id_07L</th>\n",
       "      <th>category_id_0FT</th>\n",
       "      <th>category_id_0VB</th>\n",
       "      <th>category_id_09P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74778</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74783 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       asa_3.0  asa_2.0  weight   age  height  anesth_duration  or_duration  \\\n",
       "0          0.0      0.0    66.0  50.0   157.0             70.0         45.0   \n",
       "1          0.0      0.0    62.0  60.0   154.0             90.0         70.0   \n",
       "2          0.0      1.0    50.0  35.0   160.0            150.0        115.0   \n",
       "3          0.0      1.0    62.0  20.0   179.0            135.0         90.0   \n",
       "4          0.0      0.0    52.0  60.0   152.0             90.0         30.0   \n",
       "...        ...      ...     ...   ...     ...              ...          ...   \n",
       "74778      1.0      0.0    61.0  80.0   171.0            380.0        320.0   \n",
       "74779      0.0      1.0    51.0  55.0   162.0            100.0         65.0   \n",
       "74780      0.0      1.0    60.0  80.0   160.0            150.0        120.0   \n",
       "74781      0.0      1.0    72.0  30.0   176.0            100.0         65.0   \n",
       "74782      0.0      0.0    58.0  45.0   158.0             75.0         55.0   \n",
       "\n",
       "       icu_visit  department_OT  antype_MAC  ...  category_id_09Q  \\\n",
       "0            0.0            0.0         0.0  ...              1.0   \n",
       "1            0.0            0.0         0.0  ...              1.0   \n",
       "2            0.0            1.0         1.0  ...              0.0   \n",
       "3            0.0            1.0         1.0  ...              0.0   \n",
       "4            0.0            1.0         1.0  ...              0.0   \n",
       "...          ...            ...         ...  ...              ...   \n",
       "74778        1.0            0.0         0.0  ...              0.0   \n",
       "74779        0.0            0.0         0.0  ...              0.0   \n",
       "74780        1.0            0.0         0.0  ...              0.0   \n",
       "74781        0.0            0.0         0.0  ...              0.0   \n",
       "74782        0.0            0.0         0.0  ...              0.0   \n",
       "\n",
       "       category_id_08R  category_id_0DB  category_id_0QS  category_id_0DT  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              0.0   \n",
       "...                ...              ...              ...              ...   \n",
       "74778              0.0              0.0              0.0              0.0   \n",
       "74779              0.0              0.0              0.0              0.0   \n",
       "74780              0.0              0.0              0.0              0.0   \n",
       "74781              0.0              0.0              0.0              0.0   \n",
       "74782              0.0              1.0              0.0              0.0   \n",
       "\n",
       "       category_id_0W3  category_id_07L  category_id_0FT  category_id_0VB  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              0.0   \n",
       "...                ...              ...              ...              ...   \n",
       "74778              0.0              0.0              0.0              0.0   \n",
       "74779              0.0              0.0              0.0              0.0   \n",
       "74780              0.0              0.0              0.0              0.0   \n",
       "74781              0.0              0.0              0.0              0.0   \n",
       "74782              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       category_id_09P  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "74778              0.0  \n",
       "74779              0.0  \n",
       "74780              0.0  \n",
       "74781              0.0  \n",
       "74782              0.0  \n",
       "\n",
       "[74783 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label = LOS\n",
    "\n",
    "features_to_retain = ['asa_3.0',\t'asa_2.0',\t'weight',\t'age',\t'height',\t\t'anesth_duration',\t'or_duration',\t'icu_visit',\t'department_OT',\t'antype_MAC',\t'antype_Neuraxial',\t'department_OS',\t'department_GS',\t'department_OG',\t'department_OL',\t'department_NS',\t'department_CTS',\t'department_UR',\t'ast',\t'alt',\t'total_bilirubin',\t'lymphocyte',\t'wbc',\t'art_sbp',\t'pmean',\t'art_mbp',\t'vt',\t'pip',\t'rr',\t'hr',\t'chloride',\t'hb',\t'sodium',\t'hco3',\t'platelet',\t'category_id_08D',\t'category_id_0HB',\t'category_id_09Q',\t'category_id_08R',\t'category_id_0DB',\t'category_id_0QS',\t'category_id_0DT',\t'category_id_0W3',\t'category_id_07L',\t'category_id_0FT',\t'category_id_0VB',\t'category_id_09P'] \n",
    "\n",
    "y = df['LOS']\n",
    "X = df.drop('LOS', axis=1)\n",
    "X = X[features_to_retain]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74783, 170)\n",
      "(74783, 47)\n"
     ]
    }
   ],
   "source": [
    "# Original DF\n",
    "print(df.shape)\n",
    "# X DF with dropped LOS and non-important featuresd.\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Y (LOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0     -0.447474\n",
      "1     -0.273747\n",
      "2     -0.150233\n",
      "3     -0.592920\n",
      "4     -0.587148\n",
      "...         ...\n",
      "74778  1.842721\n",
      "74779 -0.620624\n",
      "74780 -0.465943\n",
      "74781  0.040809\n",
      "74782 -0.455554\n",
      "\n",
      "[74783 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize y\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = y.values #returns a numpy array\n",
    "y = y.reshape(-1, 1)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "ynorm=pd.DataFrame(y_scaled)\n",
    "print(ynorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ynorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "- Training Set (80% of total): \n",
    "  - Used to train the models.\n",
    "- Validation Set (20% of Traning Set ): \n",
    "  - Used to fine-tune hyperparameters, select models, and monitor training progress.  \n",
    "- Testing Set (20% of total): \n",
    "  - Used to evaluate the final model's performance on unseen data and estimate its generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (47860, 47)\n",
      "X_validate shape: (11966, 47)\n",
      "X_test shape: (14957, 47)\n",
      "y_train shape: (47860, 1)\n",
      "y_validate shape: (11966, 1)\n",
      "y_test shape: (14957, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SPLIT = .2\n",
    "TRAINING_SPLIT = 1-TEST_SPLIT\n",
    "VALIDATION_SPLIT = .2\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ynorm, test_size=TEST_SPLIT, random_state=85100)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=TEST_SPLIT, random_state=85100)\n",
    "\n",
    "# Then, you can use X_train and y_train for model training and X_test and y_test for evaluation.\n",
    "\n",
    "data_subset_dict = {\n",
    "    'X_train': X_train,\n",
    "    'X_validate': X_validate,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_validate': y_validate,\n",
    "    'y_test': y_test}\n",
    "\n",
    "for key, value in data_subset_dict.items():\n",
    "    shape = value.shape\n",
    "    print(f\"{key} shape: {shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALIZE MODEL\n",
    "\n",
    "rfc_100 = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training set\n",
    "rfc_100.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the Validation set results\n",
    "y_pred_100 = rfc_100.predict(X_test)\n",
    "\n",
    "# Check accuracy score \n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an evaluation function Root Mean Squared Error:\n",
    "\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model,X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.43\n",
      "ExtraTreesRegressor: 0.62\n",
      "Random Forest: 0.58\n",
      "XGBRegressor: 0.56\n",
      "____________________________________________________________________________________________________\n",
      "Linear Regression 0.429\n",
      "XGBRegressor 0.557\n",
      "Random Forest 0.577\n",
      "ExtraTreesRegressor 0.621\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "#  SIMPLE Pipeline -\n",
    "#  -- No tuning. \n",
    "########################\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "model_list= [LinearRegression(),ExtraTreesRegressor (),RandomForestRegressor(),XGBRegressor()]\n",
    "model_names = [\"Linear Regression\",\"ExtraTreesRegressor\", \"Random Forest\",\"XGBRegressor\"]\n",
    "\n",
    "ModScores = {}\n",
    "for model_names, model in zip(model_names, model_list):\n",
    "    pipeline = Pipeline(steps=[('select_best', SelectKBest()), # Optional if not already perofrmed above: 'scaling', StandardScaler()),\n",
    "                           ('classifier', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_validate)\n",
    "\n",
    "    score = rmse_cv(model,y_validate, y_pred)\n",
    "    ModScores[model_names] = score.mean()\n",
    "    print(\"{}: {:.2f}\".format(model_names,score.mean()))\n",
    "\n",
    "print(\"_\"*100)\n",
    "for key, value in sorted(ModScores.items(), key = itemgetter(1), reverse = False):\n",
    "    print(key, round(value,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Models with Hyperparameter Tuning via Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "#  Pipeline with TUNING \n",
    "# \n",
    "########################\n",
    "from sklearn.linear_model import RandomForestRegressor,XGBRegressor,Ex\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "model_list= [ExtraTreesRegressor (),RandomForestRegressor(),XGBRegressor()]\n",
    "model_names = [\"ExtraTreesRegressor\", \"Random Forest\",\"XGBRegressor\"]\n",
    "\n",
    "# Find the best hyperparameters using GridSearchCV on the train set\n",
    "param_grids = {\n",
    "    'RandomForestRegressor': {\n",
    "                    'randomforestregressor__n_estimators': [50, 100, 200],\n",
    "                    'randomforestregressor__max_depth': [None, 10, 20, 30],\n",
    "                    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "                    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "                    'randomforestregressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'randomforestregressor__bootstrap': [True, False]\n",
    "            },          \n",
    "    'ExtraTreesRegressor':{\n",
    "                    'extratreesregressor__n_estimators': [50, 100, 200],\n",
    "                    'extratreesregressor__max_depth': [None, 10, 20, 30],\n",
    "                    'extratreesregressor__min_samples_split': [2, 5, 10],\n",
    "                    'extratreesregressor__min_samples_leaf': [1, 2, 4],\n",
    "                    'extratreesregressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'extratreesregressor__bootstrap': [True, False]\n",
    "                    },\n",
    "    'XGBRegressor': {\n",
    "                    'xgb__objective': ['reg:squarederror'],\n",
    "                    'xgb__tree_method': ['gpu_hist'],\n",
    "                    'xgb__n_estimators': [50, 100, 200],# Number of boosting rounds (trees)\n",
    "                    'xgb__learning_rate': [0.01, 0.1, 0.2],# Learning rate\n",
    "                    'xgb__max_depth': [3, 4, 5],# Maximum depth of each tree\n",
    "                    'xgb__min_child_weight': [1, 2, 3],# Minimum sum of instance weight (hessian) needed in a child\n",
    "                    'xgb__subsample': [0.8, 0.9, 1.0],# Subsample ratio of columns when constructing each tree\n",
    "                    'xgb__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "                    }\n",
    "        }\n",
    "\n",
    "ModScores = {}\n",
    "for model_name, model in zip(model_names, model_list):\n",
    "    pipeline = Pipeline(steps=[('select_best', SelectKBest()),\n",
    "                               ('classifier', model)])\n",
    "    \n",
    "     # Access the parameter grid for the current model\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_validate)\n",
    "\n",
    "    score = rmse_cv(model,y_validate, y_pred)\n",
    "    ModScores[model_names] = score.mean()\n",
    "    print(\"{}: {:.2f}\".format(model_names,score.mean()))\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_hyperparams = grid.best_params_\n",
    "    best_acc = grid.score(X_test, y_test)\n",
    "    print(f'Best test set accuracy: {best_acc}\\nAchieved with hyperparameters: {best_hyperparams}')\n",
    "\n",
    "print(\"_\"*100)\n",
    "for key, value in sorted(ModScores.items(), key = itemgetter(1), reverse = False):\n",
    "    print(key, round(value,3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
