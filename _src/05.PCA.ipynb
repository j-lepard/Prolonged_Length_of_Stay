{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: This is Python 3 code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt # NOTE: This was tested with matplotlib v. 2.1.0\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91862 entries, 0 to 91861\n",
      "Data columns (total 63 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         91862 non-null  int64  \n",
      " 1   op_id              91862 non-null  int64  \n",
      " 2   subject_id         91862 non-null  int64  \n",
      " 3   hadm_id            91862 non-null  int64  \n",
      " 4   opdate             91862 non-null  int64  \n",
      " 5   age                91862 non-null  int64  \n",
      " 6   sex                91862 non-null  object \n",
      " 7   weight             90910 non-null  float64\n",
      " 8   height             91326 non-null  float64\n",
      " 9   race               91862 non-null  object \n",
      " 10  asa                89532 non-null  float64\n",
      " 11  emop               91862 non-null  int64  \n",
      " 12  department         91862 non-null  object \n",
      " 13  antype             91862 non-null  object \n",
      " 14  icd10_pcs          91862 non-null  object \n",
      " 15  category_desc      91862 non-null  object \n",
      " 16  desc_short         91862 non-null  object \n",
      " 17  category_id        91862 non-null  object \n",
      " 18  orin_time          91862 non-null  int64  \n",
      " 19  orout_time         91862 non-null  int64  \n",
      " 20  opstart_time       91854 non-null  float64\n",
      " 21  opend_time         91854 non-null  float64\n",
      " 22  admission_time     91862 non-null  int64  \n",
      " 23  discharge_time     91862 non-null  int64  \n",
      " 24  anstart_time       91823 non-null  float64\n",
      " 25  anend_time         91612 non-null  float64\n",
      " 26  cpbon_time         2153 non-null   float64\n",
      " 27  cpboff_time        2153 non-null   float64\n",
      " 28  icuin_time         11210 non-null  float64\n",
      " 29  icuout_time        11210 non-null  float64\n",
      " 30  inhosp_death_time  969 non-null    float64\n",
      " 31  subject_id_y       91836 non-null  float64\n",
      " 32  chart_time_x       91836 non-null  float64\n",
      " 33  art_dbp            26232 non-null  float64\n",
      " 34  art_mbp            89504 non-null  float64\n",
      " 35  art_sbp            89497 non-null  float64\n",
      " 36  bt                 89479 non-null  float64\n",
      " 37  cvp                89248 non-null  float64\n",
      " 38  hr                 89515 non-null  float64\n",
      " 39  pip                89519 non-null  float64\n",
      " 40  pmean              89508 non-null  float64\n",
      " 41  rr                 89517 non-null  float64\n",
      " 42  spo2               89517 non-null  float64\n",
      " 43  vt                 89512 non-null  float64\n",
      " 44  chart_time_y       89532 non-null  float64\n",
      " 45  alp                89455 non-null  float64\n",
      " 46  alt                89465 non-null  float64\n",
      " 47  ast                89465 non-null  float64\n",
      " 48  chloride           89471 non-null  float64\n",
      " 49  creatinine         89467 non-null  float64\n",
      " 50  glucose            89527 non-null  float64\n",
      " 51  hb                 89488 non-null  float64\n",
      " 52  hco3               89520 non-null  float64\n",
      " 53  lymphocyte         89460 non-null  float64\n",
      " 54  platelet           89461 non-null  float64\n",
      " 55  potassium          89523 non-null  float64\n",
      " 56  sodium             89522 non-null  float64\n",
      " 57  total_bilirubin    89454 non-null  float64\n",
      " 58  wbc                89465 non-null  float64\n",
      " 59  LOS                89532 non-null  float64\n",
      " 60  is_outlier         91862 non-null  int64  \n",
      " 61  prolonged_LOS      91862 non-null  int64  \n",
      " 62  icu_visit          91862 non-null  bool   \n",
      "dtypes: bool(1), float64(41), int64(13), object(8)\n",
      "memory usage: 43.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Data Import\n",
    "#\n",
    "#########################\n",
    "df = pd.read_csv('../_data/operations_imputed_CLEAN.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 89532 entries, 2 to 91861\n",
      "Data columns (total 35 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              89532 non-null  int64  \n",
      " 1   sex              89532 non-null  object \n",
      " 2   weight           88611 non-null  float64\n",
      " 3   height           89054 non-null  float64\n",
      " 4   asa              89532 non-null  float64\n",
      " 5   emop             89532 non-null  int64  \n",
      " 6   department       89532 non-null  object \n",
      " 7   antype           89532 non-null  object \n",
      " 8   category_id      89532 non-null  object \n",
      " 9   art_mbp          89504 non-null  float64\n",
      " 10  art_sbp          89497 non-null  float64\n",
      " 11  bt               89479 non-null  float64\n",
      " 12  cvp              89248 non-null  float64\n",
      " 13  hr               89515 non-null  float64\n",
      " 14  pip              89519 non-null  float64\n",
      " 15  pmean            89508 non-null  float64\n",
      " 16  rr               89517 non-null  float64\n",
      " 17  spo2             89517 non-null  float64\n",
      " 18  vt               89512 non-null  float64\n",
      " 19  chart_time_y     89532 non-null  float64\n",
      " 20  alp              89455 non-null  float64\n",
      " 21  alt              89465 non-null  float64\n",
      " 22  ast              89465 non-null  float64\n",
      " 23  chloride         89471 non-null  float64\n",
      " 24  creatinine       89467 non-null  float64\n",
      " 25  glucose          89527 non-null  float64\n",
      " 26  hb               89488 non-null  float64\n",
      " 27  hco3             89520 non-null  float64\n",
      " 28  lymphocyte       89460 non-null  float64\n",
      " 29  platelet         89461 non-null  float64\n",
      " 30  potassium        89523 non-null  float64\n",
      " 31  sodium           89522 non-null  float64\n",
      " 32  total_bilirubin  89454 non-null  float64\n",
      " 33  wbc              89465 non-null  float64\n",
      " 34  icu_visit        89532 non-null  bool   \n",
      "dtypes: bool(1), float64(28), int64(2), object(4)\n",
      "memory usage: 24.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>asa</th>\n",
       "      <th>emop</th>\n",
       "      <th>department</th>\n",
       "      <th>antype</th>\n",
       "      <th>category_id</th>\n",
       "      <th>art_mbp</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose</th>\n",
       "      <th>hb</th>\n",
       "      <th>hco3</th>\n",
       "      <th>lymphocyte</th>\n",
       "      <th>platelet</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sodium</th>\n",
       "      <th>total_bilirubin</th>\n",
       "      <th>wbc</th>\n",
       "      <th>icu_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>66.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OS</td>\n",
       "      <td>General</td>\n",
       "      <td>0NQ</td>\n",
       "      <td>100.826720</td>\n",
       "      <td>...</td>\n",
       "      <td>117.007856</td>\n",
       "      <td>11.385262</td>\n",
       "      <td>24.479130</td>\n",
       "      <td>20.414394</td>\n",
       "      <td>223.140988</td>\n",
       "      <td>3.768724</td>\n",
       "      <td>139.116926</td>\n",
       "      <td>0.851504</td>\n",
       "      <td>8.957105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>62.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0GT</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>...</td>\n",
       "      <td>118.671026</td>\n",
       "      <td>11.746523</td>\n",
       "      <td>24.746791</td>\n",
       "      <td>23.938716</td>\n",
       "      <td>217.282759</td>\n",
       "      <td>3.846584</td>\n",
       "      <td>140.033084</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>8.200501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OS</td>\n",
       "      <td>Neuraxial</td>\n",
       "      <td>09B</td>\n",
       "      <td>98.084871</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>22.344397</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.310000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>62.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OL</td>\n",
       "      <td>General</td>\n",
       "      <td>09Q</td>\n",
       "      <td>92.702290</td>\n",
       "      <td>...</td>\n",
       "      <td>100.845000</td>\n",
       "      <td>14.265657</td>\n",
       "      <td>22.965854</td>\n",
       "      <td>22.134112</td>\n",
       "      <td>237.222222</td>\n",
       "      <td>4.041013</td>\n",
       "      <td>139.824013</td>\n",
       "      <td>1.078906</td>\n",
       "      <td>10.044925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OL</td>\n",
       "      <td>General</td>\n",
       "      <td>09Q</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>...</td>\n",
       "      <td>118.671026</td>\n",
       "      <td>11.746523</td>\n",
       "      <td>24.746791</td>\n",
       "      <td>23.938716</td>\n",
       "      <td>217.282759</td>\n",
       "      <td>3.846584</td>\n",
       "      <td>140.033084</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>8.200501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91857</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0DN</td>\n",
       "      <td>100.826720</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>11.385262</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>20.414394</td>\n",
       "      <td>223.140988</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.851504</td>\n",
       "      <td>8.957105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91858</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>53.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0HB</td>\n",
       "      <td>99.036609</td>\n",
       "      <td>...</td>\n",
       "      <td>131.749045</td>\n",
       "      <td>11.550836</td>\n",
       "      <td>24.812058</td>\n",
       "      <td>21.154115</td>\n",
       "      <td>212.690065</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>8.535719</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91859</th>\n",
       "      <td>65</td>\n",
       "      <td>F</td>\n",
       "      <td>51.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0HB</td>\n",
       "      <td>97.106931</td>\n",
       "      <td>...</td>\n",
       "      <td>129.145614</td>\n",
       "      <td>11.638787</td>\n",
       "      <td>24.879181</td>\n",
       "      <td>21.422042</td>\n",
       "      <td>212.006881</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>8.557983</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91860</th>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0DB</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>19.733333</td>\n",
       "      <td>218.800000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91861</th>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>78.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0FT</td>\n",
       "      <td>99.157658</td>\n",
       "      <td>...</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>12.674328</td>\n",
       "      <td>24.767561</td>\n",
       "      <td>19.047368</td>\n",
       "      <td>200.625000</td>\n",
       "      <td>4.056197</td>\n",
       "      <td>138.322951</td>\n",
       "      <td>1.037102</td>\n",
       "      <td>9.585853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89532 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age sex  weight  height  asa  emop department     antype category_id  \\\n",
       "2       50   F    66.0   157.0  2.0     0         OS    General         0NQ   \n",
       "3       60   F    62.0   154.0  1.0     0         GS    General         0GT   \n",
       "4       35   F    50.0   160.0  1.0     0         OS  Neuraxial         09B   \n",
       "5       20   M    62.0   179.0  1.0     0         OL    General         09Q   \n",
       "6       60   F    52.0   152.0  1.0     0         OL    General         09Q   \n",
       "...    ...  ..     ...     ...  ...   ...        ...        ...         ...   \n",
       "91857   50   F    58.0   162.0  2.0     0         GS    General         0DN   \n",
       "91858   70   F    53.0   162.0  2.0     0         GS    General         0HB   \n",
       "91859   65   F    51.0   152.0  2.0     0         GS    General         0HB   \n",
       "91860   85   M    74.0   171.0  4.0     0         GS    General         0DB   \n",
       "91861   70   M    78.0   182.0  2.0     0         GS    General         0FT   \n",
       "\n",
       "          art_mbp  ...     glucose         hb       hco3  lymphocyte  \\\n",
       "2      100.826720  ...  117.007856  11.385262  24.479130   20.414394   \n",
       "3      100.773779  ...  118.671026  11.746523  24.746791   23.938716   \n",
       "4       98.084871  ...   98.000000  10.400000  22.344397   13.300000   \n",
       "5       92.702290  ...  100.845000  14.265657  22.965854   22.134112   \n",
       "6      100.773779  ...  118.671026  11.746523  24.746791   23.938716   \n",
       "...           ...  ...         ...        ...        ...         ...   \n",
       "91857  100.826720  ...  127.000000  11.385262  23.700000   20.414394   \n",
       "91858   99.036609  ...  131.749045  11.550836  24.812058   21.154115   \n",
       "91859   97.106931  ...  129.145614  11.638787  24.879181   21.422042   \n",
       "91860   92.000000  ...  171.000000  11.360000  22.600000   19.733333   \n",
       "91861   99.157658  ...  185.000000  12.674328  24.767561   19.047368   \n",
       "\n",
       "         platelet  potassium      sodium  total_bilirubin        wbc  \\\n",
       "2      223.140988   3.768724  139.116926         0.851504   8.957105   \n",
       "3      217.282759   3.846584  140.033084         0.744921   8.200501   \n",
       "4      124.000000   3.900000  138.000000         0.600000   6.310000   \n",
       "5      237.222222   4.041013  139.824013         1.078906  10.044925   \n",
       "6      217.282759   3.846584  140.033084         0.744921   8.200501   \n",
       "...           ...        ...         ...              ...        ...   \n",
       "91857  223.140988   3.800000  134.000000         0.851504   8.957105   \n",
       "91858  212.690065   3.700000  142.000000         0.760224   8.535719   \n",
       "91859  212.006881   3.800000  143.000000         0.780793   8.557983   \n",
       "91860  218.800000   3.900000  137.000000         1.800000   9.932500   \n",
       "91861  200.625000   4.056197  138.322951         1.037102   9.585853   \n",
       "\n",
       "       icu_visit  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "5          False  \n",
       "6          False  \n",
       "...          ...  \n",
       "91857      False  \n",
       "91858      False  \n",
       "91859      False  \n",
       "91860       True  \n",
       "91861      False  \n",
       "\n",
       "[89532 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Perform PCA on the data\n",
    "#\n",
    "#########################\n",
    "# First center and scale the data\n",
    "\n",
    "## Drop records with NaN in 'asa' \n",
    "df = df.dropna(subset=['asa'])\n",
    "df\n",
    "\n",
    "cols_to_drop = ['Unnamed: 0','op_id','subject_id','hadm_id','opdate','LOS','is_outlier','prolonged_LOS','category_desc','desc_short','subject_id_y','inhosp_death_time','orin_time','orout_time','opstart_time','opend_time','admission_time','discharge_time','anstart_time','anend_time','cpbon_time','cpboff_time','icuin_time','icuout_time','icd10_pcs','chart_time_x','race','art_dbp','emop']\n",
    "x_df = df.drop(columns=cols_to_drop, axis=1)\n",
    "x_df.info()\n",
    "\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'department', 'antype', 'category_id']\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# One-Hot encode categorical Features\n",
    "#\n",
    "#########################\n",
    "\n",
    "# Filter columns with dtype 'object'\n",
    "object_columns = x_df.select_dtypes(include='object').columns.tolist()\n",
    "print(object_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_cat_vars(x):\n",
    "    original_cols = set(x.columns)\n",
    "    \n",
    "    x = pd.get_dummies(\n",
    "        x,\n",
    "        columns=object_columns,\n",
    "        drop_first=True,\n",
    "    )\n",
    "    \n",
    "    # Get the newly added columns by taking the difference of the sets\n",
    "    dummy_cols = list(set(x.columns) - original_cols)\n",
    "    \n",
    "    return x, dummy_cols\n",
    "\n",
    "\n",
    "#Dummy variable creation is done before spliting the data , so all the different categories are covered\n",
    "#create dummy variable\n",
    "df_encoded, dummy_columns= encode_cat_vars(x_df)\n",
    "\n",
    "#confirm:\n",
    "# df_encoded.shape\n",
    "# df_encoded\n",
    "\n",
    "df_encoded.to_csv('encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With current categories- there are 164 features after 1-ht. This may be a problem. \n",
    "Need to remember that each model will be trained on the category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamie\\OneDrive - Lepard & Lepard\\Data Science\\LighthouseLabs\\Python_Projects\\Prolonged_LOS_Project\\_src\\05.PCA.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scaled_data \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mscale(df_encoded\u001b[39m.\u001b[39mT)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA() \u001b[39m# create a PCA object\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pca\u001b[39m.\u001b[39;49mfit(scaled_data) \u001b[39m# do the math\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pca_data \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(scaled_data)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:434\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    435\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    478\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    479\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    481\u001b[0m     )\n\u001b[1;32m--> 483\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    484\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    485\u001b[0m )\n\u001b[0;32m    487\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# First center and scale the data\n",
    "scaled_data = preprocessing.scale(df_encoded.T)\n",
    " \n",
    "pca = PCA() # create a PCA object\n",
    "pca.fit(scaled_data) # do the math\n",
    "pca_data = pca.transform(scaled_data) # get PCA coordinates for scaled_data\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "#\n",
    "# Draw a scree plot and a PCA plot\n",
    "#\n",
    "#########################\n",
    " \n",
    "#The following code constructs the Scree plot\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n",
    " \n",
    "#the following code makes a fancy looking plot using PC1 and PC2\n",
    "pca_df = pd.DataFrame(pca_data, index=[*wt, *ko], columns=labels)\n",
    " \n",
    "plt.scatter(pca_df.PC1, pca_df.PC2)\n",
    "plt.title('My PCA Graph')\n",
    "plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
    "plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
    " \n",
    "for sample in pca_df.index:\n",
    "    plt.annotate(sample, (pca_df.PC1.loc[sample], pca_df.PC2.loc[sample]))\n",
    " \n",
    "plt.show()\n",
    " \n",
    "#########################\n",
    "#\n",
    "# Determine which genes had the biggest influence on PC1\n",
    "#\n",
    "#########################\n",
    " \n",
    "## get the name of the top 10 measurements (genes) that contribute\n",
    "## most to pc1.\n",
    "## first, get the loading scores\n",
    "loading_scores = pd.Series(pca.components_[0], index=genes)\n",
    "## now sort the loading scores based on their magnitude\n",
    "sorted_loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
    " \n",
    "# get the names of the top 10 genes\n",
    "top_10_genes = sorted_loading_scores[0:10].index.values\n",
    " \n",
    "## print the gene names and their scores (and +/- sign)\n",
    "print(loading_scores[top_10_genes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
