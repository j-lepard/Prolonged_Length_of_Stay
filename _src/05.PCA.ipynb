{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: This is Python 3 code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt # NOTE: This was tested with matplotlib v. 2.1.0\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91862 entries, 0 to 91861\n",
      "Data columns (total 63 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         91862 non-null  int64  \n",
      " 1   op_id              91862 non-null  int64  \n",
      " 2   subject_id         91862 non-null  int64  \n",
      " 3   hadm_id            91862 non-null  int64  \n",
      " 4   opdate             91862 non-null  int64  \n",
      " 5   age                91862 non-null  int64  \n",
      " 6   sex                91862 non-null  object \n",
      " 7   weight             90910 non-null  float64\n",
      " 8   height             91326 non-null  float64\n",
      " 9   race               91862 non-null  object \n",
      " 10  asa                89532 non-null  float64\n",
      " 11  emop               91862 non-null  int64  \n",
      " 12  department         91862 non-null  object \n",
      " 13  antype             91862 non-null  object \n",
      " 14  icd10_pcs          91862 non-null  object \n",
      " 15  category_desc      91862 non-null  object \n",
      " 16  desc_short         91862 non-null  object \n",
      " 17  category_id        91862 non-null  object \n",
      " 18  orin_time          91862 non-null  int64  \n",
      " 19  orout_time         91862 non-null  int64  \n",
      " 20  opstart_time       91854 non-null  float64\n",
      " 21  opend_time         91854 non-null  float64\n",
      " 22  admission_time     91862 non-null  int64  \n",
      " 23  discharge_time     91862 non-null  int64  \n",
      " 24  anstart_time       91823 non-null  float64\n",
      " 25  anend_time         91612 non-null  float64\n",
      " 26  cpbon_time         2153 non-null   float64\n",
      " 27  cpboff_time        2153 non-null   float64\n",
      " 28  icuin_time         11210 non-null  float64\n",
      " 29  icuout_time        11210 non-null  float64\n",
      " 30  inhosp_death_time  969 non-null    float64\n",
      " 31  subject_id_y       91836 non-null  float64\n",
      " 32  chart_time_x       91836 non-null  float64\n",
      " 33  art_dbp            26232 non-null  float64\n",
      " 34  art_mbp            89504 non-null  float64\n",
      " 35  art_sbp            89497 non-null  float64\n",
      " 36  bt                 89479 non-null  float64\n",
      " 37  cvp                89248 non-null  float64\n",
      " 38  hr                 89515 non-null  float64\n",
      " 39  pip                89519 non-null  float64\n",
      " 40  pmean              89508 non-null  float64\n",
      " 41  rr                 89517 non-null  float64\n",
      " 42  spo2               89517 non-null  float64\n",
      " 43  vt                 89512 non-null  float64\n",
      " 44  chart_time_y       89532 non-null  float64\n",
      " 45  alp                89455 non-null  float64\n",
      " 46  alt                89465 non-null  float64\n",
      " 47  ast                89465 non-null  float64\n",
      " 48  chloride           89471 non-null  float64\n",
      " 49  creatinine         89467 non-null  float64\n",
      " 50  glucose            89527 non-null  float64\n",
      " 51  hb                 89488 non-null  float64\n",
      " 52  hco3               89520 non-null  float64\n",
      " 53  lymphocyte         89460 non-null  float64\n",
      " 54  platelet           89461 non-null  float64\n",
      " 55  potassium          89523 non-null  float64\n",
      " 56  sodium             89522 non-null  float64\n",
      " 57  total_bilirubin    89454 non-null  float64\n",
      " 58  wbc                89465 non-null  float64\n",
      " 59  LOS                89532 non-null  float64\n",
      " 60  is_outlier         91862 non-null  int64  \n",
      " 61  prolonged_LOS      91862 non-null  int64  \n",
      " 62  icu_visit          91862 non-null  bool   \n",
      "dtypes: bool(1), float64(41), int64(13), object(8)\n",
      "memory usage: 43.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Data Import\n",
    "#\n",
    "#########################\n",
    "df = pd.read_csv('../_data/operations_imputed_CLEAN.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 89532 entries, 2 to 91861\n",
      "Data columns (total 35 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              89532 non-null  int64  \n",
      " 1   sex              89532 non-null  object \n",
      " 2   weight           88611 non-null  float64\n",
      " 3   height           89054 non-null  float64\n",
      " 4   asa              89532 non-null  float64\n",
      " 5   department       89532 non-null  object \n",
      " 6   antype           89532 non-null  object \n",
      " 7   category_id      89532 non-null  object \n",
      " 8   art_mbp          89504 non-null  float64\n",
      " 9   art_sbp          89497 non-null  float64\n",
      " 10  bt               89479 non-null  float64\n",
      " 11  cvp              89248 non-null  float64\n",
      " 12  hr               89515 non-null  float64\n",
      " 13  pip              89519 non-null  float64\n",
      " 14  pmean            89508 non-null  float64\n",
      " 15  rr               89517 non-null  float64\n",
      " 16  spo2             89517 non-null  float64\n",
      " 17  vt               89512 non-null  float64\n",
      " 18  chart_time_y     89532 non-null  float64\n",
      " 19  alp              89455 non-null  float64\n",
      " 20  alt              89465 non-null  float64\n",
      " 21  ast              89465 non-null  float64\n",
      " 22  chloride         89471 non-null  float64\n",
      " 23  creatinine       89467 non-null  float64\n",
      " 24  glucose          89527 non-null  float64\n",
      " 25  hb               89488 non-null  float64\n",
      " 26  hco3             89520 non-null  float64\n",
      " 27  lymphocyte       89460 non-null  float64\n",
      " 28  platelet         89461 non-null  float64\n",
      " 29  potassium        89523 non-null  float64\n",
      " 30  sodium           89522 non-null  float64\n",
      " 31  total_bilirubin  89454 non-null  float64\n",
      " 32  wbc              89465 non-null  float64\n",
      " 33  LOS              89532 non-null  float64\n",
      " 34  icu_visit        89532 non-null  bool   \n",
      "dtypes: bool(1), float64(29), int64(1), object(4)\n",
      "memory usage: 26.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>asa</th>\n",
       "      <th>department</th>\n",
       "      <th>antype</th>\n",
       "      <th>category_id</th>\n",
       "      <th>art_mbp</th>\n",
       "      <th>art_sbp</th>\n",
       "      <th>...</th>\n",
       "      <th>hb</th>\n",
       "      <th>hco3</th>\n",
       "      <th>lymphocyte</th>\n",
       "      <th>platelet</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sodium</th>\n",
       "      <th>total_bilirubin</th>\n",
       "      <th>wbc</th>\n",
       "      <th>LOS</th>\n",
       "      <th>icu_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>66.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OS</td>\n",
       "      <td>General</td>\n",
       "      <td>0NQ</td>\n",
       "      <td>100.826720</td>\n",
       "      <td>137.244265</td>\n",
       "      <td>...</td>\n",
       "      <td>11.385262</td>\n",
       "      <td>24.479130</td>\n",
       "      <td>20.414394</td>\n",
       "      <td>223.140988</td>\n",
       "      <td>3.768724</td>\n",
       "      <td>139.116926</td>\n",
       "      <td>0.851504</td>\n",
       "      <td>8.957105</td>\n",
       "      <td>2.447917</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>62.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0GT</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>138.601562</td>\n",
       "      <td>...</td>\n",
       "      <td>11.746523</td>\n",
       "      <td>24.746791</td>\n",
       "      <td>23.938716</td>\n",
       "      <td>217.282759</td>\n",
       "      <td>3.846584</td>\n",
       "      <td>140.033084</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>8.200501</td>\n",
       "      <td>3.493056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OS</td>\n",
       "      <td>Neuraxial</td>\n",
       "      <td>09B</td>\n",
       "      <td>98.084871</td>\n",
       "      <td>131.646617</td>\n",
       "      <td>...</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>22.344397</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.310000</td>\n",
       "      <td>4.236111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>62.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OL</td>\n",
       "      <td>General</td>\n",
       "      <td>09Q</td>\n",
       "      <td>92.702290</td>\n",
       "      <td>140.826772</td>\n",
       "      <td>...</td>\n",
       "      <td>14.265657</td>\n",
       "      <td>22.965854</td>\n",
       "      <td>22.134112</td>\n",
       "      <td>237.222222</td>\n",
       "      <td>4.041013</td>\n",
       "      <td>139.824013</td>\n",
       "      <td>1.078906</td>\n",
       "      <td>10.044925</td>\n",
       "      <td>1.572917</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OL</td>\n",
       "      <td>General</td>\n",
       "      <td>09Q</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>138.601562</td>\n",
       "      <td>...</td>\n",
       "      <td>11.746523</td>\n",
       "      <td>24.746791</td>\n",
       "      <td>23.938716</td>\n",
       "      <td>217.282759</td>\n",
       "      <td>3.846584</td>\n",
       "      <td>140.033084</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>8.200501</td>\n",
       "      <td>1.607639</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91857</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0DN</td>\n",
       "      <td>100.826720</td>\n",
       "      <td>137.244265</td>\n",
       "      <td>...</td>\n",
       "      <td>11.385262</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>20.414394</td>\n",
       "      <td>223.140988</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.851504</td>\n",
       "      <td>8.957105</td>\n",
       "      <td>8.378472</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91858</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>53.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0HB</td>\n",
       "      <td>99.036609</td>\n",
       "      <td>142.337732</td>\n",
       "      <td>...</td>\n",
       "      <td>11.550836</td>\n",
       "      <td>24.812058</td>\n",
       "      <td>21.154115</td>\n",
       "      <td>212.690065</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>8.535719</td>\n",
       "      <td>2.614583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91859</th>\n",
       "      <td>65</td>\n",
       "      <td>F</td>\n",
       "      <td>51.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0HB</td>\n",
       "      <td>97.106931</td>\n",
       "      <td>138.279011</td>\n",
       "      <td>...</td>\n",
       "      <td>11.638787</td>\n",
       "      <td>24.879181</td>\n",
       "      <td>21.422042</td>\n",
       "      <td>212.006881</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>8.557983</td>\n",
       "      <td>5.447917</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91860</th>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0DB</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>19.733333</td>\n",
       "      <td>218.800000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>9.309028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91861</th>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>78.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GS</td>\n",
       "      <td>General</td>\n",
       "      <td>0FT</td>\n",
       "      <td>99.157658</td>\n",
       "      <td>142.864730</td>\n",
       "      <td>...</td>\n",
       "      <td>12.674328</td>\n",
       "      <td>24.767561</td>\n",
       "      <td>19.047368</td>\n",
       "      <td>200.625000</td>\n",
       "      <td>4.056197</td>\n",
       "      <td>138.322951</td>\n",
       "      <td>1.037102</td>\n",
       "      <td>9.585853</td>\n",
       "      <td>1.614583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89532 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age sex  weight  height  asa department     antype category_id  \\\n",
       "2       50   F    66.0   157.0  2.0         OS    General         0NQ   \n",
       "3       60   F    62.0   154.0  1.0         GS    General         0GT   \n",
       "4       35   F    50.0   160.0  1.0         OS  Neuraxial         09B   \n",
       "5       20   M    62.0   179.0  1.0         OL    General         09Q   \n",
       "6       60   F    52.0   152.0  1.0         OL    General         09Q   \n",
       "...    ...  ..     ...     ...  ...        ...        ...         ...   \n",
       "91857   50   F    58.0   162.0  2.0         GS    General         0DN   \n",
       "91858   70   F    53.0   162.0  2.0         GS    General         0HB   \n",
       "91859   65   F    51.0   152.0  2.0         GS    General         0HB   \n",
       "91860   85   M    74.0   171.0  4.0         GS    General         0DB   \n",
       "91861   70   M    78.0   182.0  2.0         GS    General         0FT   \n",
       "\n",
       "          art_mbp     art_sbp  ...         hb       hco3  lymphocyte  \\\n",
       "2      100.826720  137.244265  ...  11.385262  24.479130   20.414394   \n",
       "3      100.773779  138.601562  ...  11.746523  24.746791   23.938716   \n",
       "4       98.084871  131.646617  ...  10.400000  22.344397   13.300000   \n",
       "5       92.702290  140.826772  ...  14.265657  22.965854   22.134112   \n",
       "6      100.773779  138.601562  ...  11.746523  24.746791   23.938716   \n",
       "...           ...         ...  ...        ...        ...         ...   \n",
       "91857  100.826720  137.244265  ...  11.385262  23.700000   20.414394   \n",
       "91858   99.036609  142.337732  ...  11.550836  24.812058   21.154115   \n",
       "91859   97.106931  138.279011  ...  11.638787  24.879181   21.422042   \n",
       "91860   92.000000  152.000000  ...  11.360000  22.600000   19.733333   \n",
       "91861   99.157658  142.864730  ...  12.674328  24.767561   19.047368   \n",
       "\n",
       "         platelet  potassium      sodium  total_bilirubin        wbc  \\\n",
       "2      223.140988   3.768724  139.116926         0.851504   8.957105   \n",
       "3      217.282759   3.846584  140.033084         0.744921   8.200501   \n",
       "4      124.000000   3.900000  138.000000         0.600000   6.310000   \n",
       "5      237.222222   4.041013  139.824013         1.078906  10.044925   \n",
       "6      217.282759   3.846584  140.033084         0.744921   8.200501   \n",
       "...           ...        ...         ...              ...        ...   \n",
       "91857  223.140988   3.800000  134.000000         0.851504   8.957105   \n",
       "91858  212.690065   3.700000  142.000000         0.760224   8.535719   \n",
       "91859  212.006881   3.800000  143.000000         0.780793   8.557983   \n",
       "91860  218.800000   3.900000  137.000000         1.800000   9.932500   \n",
       "91861  200.625000   4.056197  138.322951         1.037102   9.585853   \n",
       "\n",
       "            LOS  icu_visit  \n",
       "2      2.447917      False  \n",
       "3      3.493056      False  \n",
       "4      4.236111      False  \n",
       "5      1.572917      False  \n",
       "6      1.607639      False  \n",
       "...         ...        ...  \n",
       "91857  8.378472      False  \n",
       "91858  2.614583      False  \n",
       "91859  5.447917      False  \n",
       "91860  9.309028       True  \n",
       "91861  1.614583      False  \n",
       "\n",
       "[89532 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Drop Target Column, NaN columns and excluded Features\n",
    "#\n",
    "#########################\n",
    "# \n",
    "## Drop records with NaN in 'asa' \n",
    "df = df.dropna(subset=['asa'])\n",
    "df\n",
    "\n",
    "## Drop Targets\n",
    "y_target_cat = 'prolonged_LOS'\n",
    "y_target_reg = 'LOS'\n",
    "\n",
    "## Drop Excluded Features\n",
    "\n",
    "cols_to_drop = [y_target_reg,'Unnamed: 0','op_id','subject_id','hadm_id','opdate','is_outlier','category_desc','desc_short','subject_id_y','inhosp_death_time','orin_time','orout_time','opstart_time','opend_time','admission_time','discharge_time','anstart_time','anend_time','cpbon_time','cpboff_time','icuin_time','icuout_time','icd10_pcs','chart_time_x','race','art_dbp','emop']\n",
    "\n",
    "# Confrim\n",
    "x_df = df.drop(columns=cols_to_drop, axis=1)\n",
    "x_df.info()\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'department', 'antype', 'category_id']\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# One-Hot encode categorical Features\n",
    "#\n",
    "#########################\n",
    "\n",
    "# Filter columns with dtype 'object'\n",
    "object_columns = x_df.select_dtypes(include='object').columns.tolist()\n",
    "print(object_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## use OneHot instead of get_dummies\n",
    "        \n",
    "def encode_cat_vars(x):\n",
    "    original_cols = set(x.columns)\n",
    "    \n",
    "    # Extract the object columns\n",
    "    object_columns = [col for col in x.columns if x[col].dtype == 'object']\n",
    "    \n",
    "    # Initialize the OneHotEncoder\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    \n",
    "    # Fit and transform the encoder on the object columns\n",
    "    encoded_data = encoder.fit_transform(x[object_columns])\n",
    "    \n",
    "    # Create a DataFrame from the encoded data with appropriate column names\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(object_columns))\n",
    "    \n",
    "    # Drop the original object columns\n",
    "    x = x.drop(object_columns, axis=1)\n",
    "    \n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    x = pd.concat([x, encoded_df], axis=1)\n",
    "    \n",
    "    # Get the newly added columns\n",
    "    dummy_cols = list(set(x.columns) - original_cols)\n",
    "    \n",
    "    return x, dummy_cols\n",
    "\n",
    "# Dummy variable creation is done before splitting the data, so all the different categories are covered\n",
    "# Create dummy variables\n",
    "df_encoded, dummy_columns = encode_cat_vars(x_df)\n",
    "\n",
    "#confirm:\n",
    "df_encoded = df_encoded.dropna(subset=['LOS'])\n",
    "df_encoded.shape\n",
    "df_encoded.to_csv('encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With current categories- there are 164 features after 1-ht. This may be a problem. \n",
    "Need to remember that each model will be trained on the category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prolonged_LOS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prolonged_LOS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamie\\OneDrive - Lepard & Lepard\\Data Science\\LighthouseLabs\\Python_Projects\\Prolonged_LOS_Project\\_src\\05.PCA.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Initialize the HistGradientBoostingClassifier for feature selection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m gbdt \u001b[39m=\u001b[39m HistGradientBoostingClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m gbdt\u001b[39m.\u001b[39mfit(df_encoded[object_columns], df_encoded[target_column])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Get feature importances from the trained GBDT model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/05.PCA.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m feature_importances \u001b[39m=\u001b[39m gbdt\u001b[39m.\u001b[39mfeature_importances_\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prolonged_LOS'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "#########################\n",
    "#\n",
    "# Principal Component Analysis - PCA\n",
    "#\n",
    "#########################\n",
    "# \n",
    "target_column = y_target_cat  # Replace with the y_regression if want to change model to regression. \n",
    "object_columns = [col for col in df_encoded.columns if col != target_column]\n",
    "\n",
    "# Initialize the HistGradientBoostingClassifier for feature selection\n",
    "gbdt = HistGradientBoostingClassifier(random_state=0)\n",
    "gbdt.fit(df_encoded[object_columns], df_encoded[target_column])\n",
    "\n",
    "# Get feature importances from the trained GBDT model\n",
    "feature_importances = gbdt.feature_importances_\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "# Select the top N most important features (you can adjust N as needed)\n",
    "num_selected_features = 8  # revise thise following our skree plot (below)\n",
    "selected_feature_indices = sorted_indices[:num_selected_features]\n",
    "\n",
    "# Extract the selected features from your DataFrame\n",
    "selected_features = df_encoded.iloc[:, selected_feature_indices]\n",
    "\n",
    "# Now, you can perform PCA on the selected features\n",
    "scaled_data = selected_features.values  # Convert to NumPy array\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Troubleshoot any NaN values in PCA\n",
    "#\n",
    "#########################\n",
    "\n",
    "df_encoded[y_target_reg].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "#\n",
    "# Draw a scree plot and a PCA plot\n",
    "#\n",
    "#########################\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#The following code constructs the Scree plot\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n",
    " \n",
    "#the following code makes a fancy looking plot using PC1 and PC2\n",
    "pca_df = pd.DataFrame(pca_data, index=[*wt, *ko], columns=labels)\n",
    " \n",
    "plt.scatter(pca_df.PC1, pca_df.PC2)\n",
    "plt.title('My PCA Graph')\n",
    "plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
    "plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
    " \n",
    "for sample in pca_df.index:\n",
    "    plt.annotate(sample, (pca_df.PC1.loc[sample], pca_df.PC2.loc[sample]))\n",
    " \n",
    "plt.show()\n",
    " \n",
    "#########################\n",
    "#\n",
    "# Determine which genes had the biggest influence on PC1\n",
    "#\n",
    "#########################\n",
    " \n",
    "## get the name of the top 10 measurements (genes) that contribute\n",
    "## most to pc1.\n",
    "## first, get the loading scores\n",
    "loading_scores = pd.Series(pca.components_[0], index=genes)\n",
    "## now sort the loading scores based on their magnitude\n",
    "sorted_loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
    " \n",
    "# get the names of the top 10 genes\n",
    "top_10_genes = sorted_loading_scores[0:10].index.values\n",
    " \n",
    "## print the gene names and their scores (and +/- sign)\n",
    "print(loading_scores[top_10_genes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
