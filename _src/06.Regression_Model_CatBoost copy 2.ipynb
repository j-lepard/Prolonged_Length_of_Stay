{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Pre-Processing\n",
    "* Missing values HAVE been imputed.\n",
    "* No PCA performed yet, no 1hot encoding. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#\n",
    "# Import Data from PreProcessing\n",
    "#\n",
    "#####################\n",
    "\n",
    "df= pd.read_csv('../_data/operations_imputed_CLEAN_v2.csv', index_col=0)\n",
    "\n",
    "df.drop(['race'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76742 entries, 8 to 128030\n",
      "Data columns (total 37 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   op_id            76742 non-null  int64  \n",
      " 1   subject_id       76742 non-null  int64  \n",
      " 2   hadm_id          76742 non-null  int64  \n",
      " 3   opdate           76742 non-null  int64  \n",
      " 4   age              76742 non-null  int64  \n",
      " 5   sex              76742 non-null  object \n",
      " 6   weight           76742 non-null  float64\n",
      " 7   height           76742 non-null  float64\n",
      " 8   asa              76742 non-null  float64\n",
      " 9   department       76742 non-null  object \n",
      " 10  antype           76742 non-null  object \n",
      " 11  icd10_pcs        76742 non-null  object \n",
      " 12  category_desc    76742 non-null  object \n",
      " 13  desc_short       76742 non-null  object \n",
      " 14  category_id      76742 non-null  object \n",
      " 15  hr               76742 non-null  float64\n",
      " 16  pip              76742 non-null  float64\n",
      " 17  pmean            76742 non-null  float64\n",
      " 18  rr               76742 non-null  float64\n",
      " 19  spo2             76742 non-null  float64\n",
      " 20  vt               76742 non-null  float64\n",
      " 21  chloride         76742 non-null  float64\n",
      " 22  creatinine       76742 non-null  float64\n",
      " 23  glucose          76742 non-null  float64\n",
      " 24  hb               76742 non-null  float64\n",
      " 25  hco3             76742 non-null  float64\n",
      " 26  lymphocyte       76742 non-null  float64\n",
      " 27  platelet         76742 non-null  float64\n",
      " 28  potassium        76742 non-null  float64\n",
      " 29  sodium           76742 non-null  float64\n",
      " 30  total_bilirubin  76742 non-null  float64\n",
      " 31  wbc              76742 non-null  float64\n",
      " 32  LOS              76742 non-null  float64\n",
      " 33  prolonged_LOS    76742 non-null  int64  \n",
      " 34  icu_visit        76742 non-null  int64  \n",
      " 35  or_duration      76742 non-null  float64\n",
      " 36  anesth_duration  76742 non-null  float64\n",
      "dtypes: float64(23), int64(7), object(7)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the X and y DataFrames\n",
    "\n",
    "  * create y\n",
    "  * create X (complete with all the features)\n",
    "  * drop the features we identified as not meeting impact threshold.\n",
    "  *  * Target = `LOS` (continuous variable)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76742 entries, 8 to 128030\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   category_id      76742 non-null  object \n",
      " 1   age              76742 non-null  int64  \n",
      " 2   sex              76742 non-null  object \n",
      " 3   weight           76742 non-null  float64\n",
      " 4   height           76742 non-null  float64\n",
      " 5   hr               76742 non-null  float64\n",
      " 6   pip              76742 non-null  float64\n",
      " 7   pmean            76742 non-null  float64\n",
      " 8   rr               76742 non-null  float64\n",
      " 9   spo2             76742 non-null  float64\n",
      " 10  vt               76742 non-null  float64\n",
      " 11  chloride         76742 non-null  float64\n",
      " 12  creatinine       76742 non-null  float64\n",
      " 13  glucose          76742 non-null  float64\n",
      " 14  hb               76742 non-null  float64\n",
      " 15  hco3             76742 non-null  float64\n",
      " 16  lymphocyte       76742 non-null  float64\n",
      " 17  platelet         76742 non-null  float64\n",
      " 18  potassium        76742 non-null  float64\n",
      " 19  sodium           76742 non-null  float64\n",
      " 20  total_bilirubin  76742 non-null  float64\n",
      " 21  wbc              76742 non-null  float64\n",
      " 22  icu_visit        76742 non-null  int64  \n",
      " 23  or_duration      76742 non-null  float64\n",
      " 24  anesth_duration  76742 non-null  float64\n",
      " 25  department       76742 non-null  object \n",
      " 26  antype           76742 non-null  object \n",
      "dtypes: float64(21), int64(2), object(4)\n",
      "memory usage: 16.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# When doing a Categorical Model, reinsert 'prolonged_LOS' and instead, drop 'LOS'\n",
    "\n",
    "## Features to retain are those in X that will be used in training. Exludued features are features such as Operation_ID, Subject_ID..\n",
    "features_to_retain = ['category_id','age','sex',\t'weight',\t'height',\t'hr',\t'pip',\t'pmean',\t'rr',\t'spo2',\t'vt',\t'chloride',\t'creatinine',\t'glucose',\t'hb',\t'hco3',\t'lymphocyte',\t'platelet',\t'potassium',\t'sodium',\t'total_bilirubin',\t'wbc',\t'icu_visit',\t'or_duration',\t'anesth_duration',\t'department','antype'] \n",
    "\n",
    "## Create the Y, the Target\n",
    "y = df['LOS']\n",
    "\n",
    "## Create X the Features for Train/Test/Validate\n",
    "X = df.drop('LOS', axis=1)\n",
    "X= X[features_to_retain]\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Features to be either cast as Str or Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Cols to encode: ['category_id', 'antype', 'sex', 'department']\n",
      "Numerical Cols to scale: Index(['age', 'weight', 'height', 'hr', 'pip', 'pmean', 'rr', 'spo2', 'vt',\n",
      "       'chloride', 'creatinine', 'glucose', 'hb', 'hco3', 'lymphocyte',\n",
      "       'platelet', 'potassium', 'sodium', 'total_bilirubin', 'wbc',\n",
      "       'icu_visit', 'or_duration', 'anesth_duration'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76742 entries, 8 to 128030\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   category_id      76742 non-null  object \n",
      " 1   age              76742 non-null  int64  \n",
      " 2   sex              76742 non-null  object \n",
      " 3   weight           76742 non-null  float64\n",
      " 4   height           76742 non-null  float64\n",
      " 5   hr               76742 non-null  float64\n",
      " 6   pip              76742 non-null  float64\n",
      " 7   pmean            76742 non-null  float64\n",
      " 8   rr               76742 non-null  float64\n",
      " 9   spo2             76742 non-null  float64\n",
      " 10  vt               76742 non-null  float64\n",
      " 11  chloride         76742 non-null  float64\n",
      " 12  creatinine       76742 non-null  float64\n",
      " 13  glucose          76742 non-null  float64\n",
      " 14  hb               76742 non-null  float64\n",
      " 15  hco3             76742 non-null  float64\n",
      " 16  lymphocyte       76742 non-null  float64\n",
      " 17  platelet         76742 non-null  float64\n",
      " 18  potassium        76742 non-null  float64\n",
      " 19  sodium           76742 non-null  float64\n",
      " 20  total_bilirubin  76742 non-null  float64\n",
      " 21  wbc              76742 non-null  float64\n",
      " 22  icu_visit        76742 non-null  int64  \n",
      " 23  or_duration      76742 non-null  float64\n",
      " 24  anesth_duration  76742 non-null  float64\n",
      " 25  department       76742 non-null  object \n",
      " 26  antype           76742 non-null  object \n",
      "dtypes: float64(21), int64(2), object(4)\n",
      "memory usage: 16.4+ MB\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "#  Identify the columns that need to be either cast as Str or Scaled\n",
    "#\n",
    "############################################################\n",
    "\n",
    "#Category Columns that will need encoding. Cast them as String\n",
    "COLS_TO_CAST = ['category_id','antype','sex','department']  #When restoring scope to full category list, add cat_id here.\n",
    "                                                            # Convert the object data type columns to string\n",
    "\n",
    "X[COLS_TO_CAST] = X[COLS_TO_CAST].astype(str)\n",
    "\n",
    "# Numerical Columns for Scaling. Filter columns with dtype 'numeric' for scaling later in the Pipleine\n",
    "COLS_TO_SCALE = X.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "\n",
    "print(f'Category Cols to encode: {COLS_TO_CAST}')\n",
    "print(f'Numerical Cols to scale: {COLS_TO_SCALE}')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-Test-Validation Split\n",
    "\n",
    "- Training Set (80% of total): \n",
    "  - Used to train the models.\n",
    "- Validation Set (20% of Traning Set ): \n",
    "  - Used to fine-tune hyperparameters, select models, and monitor training progress.  \n",
    "- Testing Set (20% of total): \n",
    "  - Used to evaluate the final model's performance on unseen data and estimate its generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49114, 27)\n",
      "X_validate shape: (12279, 27)\n",
      "X_test shape: (15349, 27)\n",
      "y_train shape: (49114,)\n",
      "y_validate shape: (12279,)\n",
      "y_test shape: (15349,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SPLIT = .2\n",
    "TRAINING_SPLIT = 1-TEST_SPLIT\n",
    "VALIDATION_SPLIT = .2\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=85100)\n",
    "\n",
    "# Split the Training AGAIN into train and Validate\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=TEST_SPLIT, random_state=85100)\n",
    "\n",
    "# use X_train and y_train for model training and X_val and y_val for turning.\n",
    "\n",
    "data_subset_dict = {\n",
    "    'X_train': X_train,\n",
    "    'X_validate': X_validate,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_validate': y_validate,\n",
    "    'y_test': y_test}\n",
    "\n",
    "for key, value in data_subset_dict.items():\n",
    "    shape = value.shape\n",
    "    print(f\"{key} shape: {shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale X (Numerical)\n",
    "* We do NOT scale Y, the target\n",
    "* We fit the StandardScaler on X_training and then transform both your training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "## SCALE X_train and X_validate\n",
    "#########\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "                ('num', StandardScaler(), COLS_TO_SCALE)\n",
    "                ],\n",
    "    remainder='passthrough')  # Leaves the rest of the columns alone\n",
    "\n",
    "# Fit on the training data\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Transform the training and validation data\n",
    "X_train_scaled = preprocessor.transform(X_train)\n",
    "X_validate_scaled = preprocessor.transform(X_validate)\n",
    "\n",
    "# Now X_train_scaled and X_validate_scaled have the specified columns scaled, and the rest are unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of base model: -2.904623057685253e+18\n",
      "RMSE of the base model: 9515250466.184\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "#  SIMPLE LINEAR REGRESSION Pipeline -\n",
    "#  -- No tuning. \n",
    "########################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "categorical_transform = Pipeline([('one-hot-encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessing_df = ColumnTransformer([('categorical', categorical_transform, COLS_TO_CAST)])\n",
    "\n",
    "pipeline_base = Pipeline([('preprocessing', preprocessing_df),\n",
    "                          ('model', LinearRegression())])\n",
    "pipeline_base.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_base.predict(X_validate)\n",
    "r2 = r2_score(y_validate, y_pred)\n",
    "rmse = mean_squared_error(y_validate, y_pred, squared=False)\n",
    "print(f'R-squared of base model: {r2}')\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;one-hot-encode&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;category_id&#x27;, &#x27;antype&#x27;,\n",
       "                                                   &#x27;sex&#x27;, &#x27;department&#x27;])])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;one-hot-encode&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;category_id&#x27;, &#x27;antype&#x27;,\n",
       "                                                   &#x27;sex&#x27;, &#x27;department&#x27;])])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one-hot-encode&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;category_id&#x27;, &#x27;antype&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;department&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;category_id&#x27;, &#x27;antype&#x27;, &#x27;sex&#x27;, &#x27;department&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('one-hot-encode',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['category_id', 'antype',\n",
       "                                                   'sex', 'department'])])),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models - Baselines  \n",
    "\n",
    "Models employed:\n",
    "* ExtraTreesRegressor\n",
    "* Random Forest\n",
    "* XGBRegressor\n",
    "* CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(): R2: -2904623057685253120.00, RMSE: 9515250466.18\n",
      "ExtraTreesRegressor(n_jobs=-1): R2: 0.48, RMSE: 4.03\n",
      "RandomForestRegressor(n_jobs=-1): R2: 0.49, RMSE: 3.99\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...): R2: 0.49, RMSE: 4.00\n",
      "____________________________________________________________________________________________________\n",
      "Random Forest: RMSE: 3.995\n",
      "XGBRegressor: RMSE: 4.004\n",
      "ExtraTreesRegressor: RMSE: 4.032\n",
      "Linear Regression: RMSE: 9515250466.184\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "#  Ensemble Pipeline -\n",
    "#  -- No tuning. \n",
    "########################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_list= [LinearRegression(),ExtraTreesRegressor (n_jobs=-1),RandomForestRegressor(n_jobs=-1),XGBRegressor(n_jobs=-1)]\n",
    "model_names = [\"Linear Regression\",\"ExtraTreesRegressor\", \"Random Forest\",\"XGBRegressor\"]\n",
    "\n",
    "\n",
    "ModScores = {}\n",
    "\n",
    "categorical_transform = Pipeline([('one-hot-encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessing_df = ColumnTransformer([('categorical', categorical_transform, COLS_TO_CAST)])\n",
    "\n",
    "for model_names, model in zip(model_names, model_list):\n",
    "    pipeline_base = Pipeline([('preprocessing', preprocessing_df),\n",
    "                          ('model', model)])\n",
    "    pipeline_base.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipeline_base.predict(X_validate)\n",
    "    \n",
    "    # Calculate the R-squared value\n",
    "    r2 = r2_score(y_validate, y_pred)\n",
    "    rmse = mean_squared_error(y_validate, y_pred, squared=False)\n",
    "    \n",
    "    ModScores[model_names] = rmse\n",
    "    \n",
    "    print(f\"{model}: R2: {r2:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "print(\"_\"*100)\n",
    "for key, value in sorted(ModScores.items(), key=itemgetter(1), reverse=False):\n",
    "    print(f\"{key}: RMSE: {value:.3f}\")\n",
    "\n",
    "########################\n",
    "## Output:\n",
    "########################\n",
    "'''Random Forest: RMSE: 3.995\n",
    "XGBRegressor: RMSE: 4.004\n",
    "ExtraTreesRegressor: RMSE: 4.032\n",
    "Linear Regression: RMSE: 9515250466.184'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c104d1289444bca3266ede87d77194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.093846\n",
      "0:\tlearn: 5.5148482\ttest: 5.4211266\tbest: 5.4211266 (0)\ttotal: 213ms\tremaining: 3m 32s\n",
      "10:\tlearn: 4.5623259\ttest: 4.5020560\tbest: 4.5020560 (10)\ttotal: 742ms\tremaining: 1m 6s\n",
      "20:\tlearn: 4.2514732\ttest: 4.2277254\tbest: 4.2277254 (20)\ttotal: 1.28s\tremaining: 59.5s\n",
      "30:\tlearn: 4.1334826\ttest: 4.1587069\tbest: 4.1587069 (30)\ttotal: 1.75s\tremaining: 54.6s\n",
      "40:\tlearn: 4.0497555\ttest: 4.0922750\tbest: 4.0922750 (40)\ttotal: 2.24s\tremaining: 52.4s\n",
      "50:\tlearn: 3.9980225\ttest: 4.0638771\tbest: 4.0638771 (50)\ttotal: 2.73s\tremaining: 50.8s\n",
      "60:\tlearn: 3.9485401\ttest: 4.0401387\tbest: 4.0401387 (60)\ttotal: 3.21s\tremaining: 49.4s\n",
      "70:\tlearn: 3.9186802\ttest: 4.0255800\tbest: 4.0255800 (70)\ttotal: 3.76s\tremaining: 49.2s\n",
      "80:\tlearn: 3.8812695\ttest: 4.0132713\tbest: 4.0132713 (80)\ttotal: 4.29s\tremaining: 48.6s\n",
      "90:\tlearn: 3.8490782\ttest: 3.9983127\tbest: 3.9983127 (90)\ttotal: 4.77s\tremaining: 47.7s\n",
      "100:\tlearn: 3.8198982\ttest: 3.9957724\tbest: 3.9957724 (100)\ttotal: 5.28s\tremaining: 47s\n",
      "110:\tlearn: 3.7918961\ttest: 3.9799529\tbest: 3.9799529 (110)\ttotal: 5.76s\tremaining: 46.2s\n",
      "120:\tlearn: 3.7761555\ttest: 3.9746378\tbest: 3.9746378 (120)\ttotal: 6.25s\tremaining: 45.4s\n",
      "130:\tlearn: 3.7571371\ttest: 3.9694294\tbest: 3.9694294 (130)\ttotal: 6.78s\tremaining: 45s\n",
      "140:\tlearn: 3.7421902\ttest: 3.9676172\tbest: 3.9673230 (139)\ttotal: 7.3s\tremaining: 44.5s\n",
      "150:\tlearn: 3.7145386\ttest: 3.9497323\tbest: 3.9497323 (150)\ttotal: 7.79s\tremaining: 43.8s\n",
      "160:\tlearn: 3.6986841\ttest: 3.9459194\tbest: 3.9459194 (160)\ttotal: 8.29s\tremaining: 43.2s\n",
      "170:\tlearn: 3.6789386\ttest: 3.9430284\tbest: 3.9430284 (170)\ttotal: 8.79s\tremaining: 42.6s\n",
      "180:\tlearn: 3.6628775\ttest: 3.9367339\tbest: 3.9367339 (180)\ttotal: 9.26s\tremaining: 41.9s\n",
      "190:\tlearn: 3.6477521\ttest: 3.9365890\tbest: 3.9360849 (182)\ttotal: 9.75s\tremaining: 41.3s\n",
      "200:\tlearn: 3.6323925\ttest: 3.9338531\tbest: 3.9338531 (200)\ttotal: 10.2s\tremaining: 40.7s\n",
      "210:\tlearn: 3.6199888\ttest: 3.9328731\tbest: 3.9325064 (206)\ttotal: 10.8s\tremaining: 40.3s\n",
      "220:\tlearn: 3.6060714\ttest: 3.9316787\tbest: 3.9297247 (218)\ttotal: 11.3s\tremaining: 39.7s\n",
      "230:\tlearn: 3.5922804\ttest: 3.9286866\tbest: 3.9286866 (230)\ttotal: 11.7s\tremaining: 39.1s\n",
      "240:\tlearn: 3.5793285\ttest: 3.9277176\tbest: 3.9276882 (239)\ttotal: 12.2s\tremaining: 38.5s\n",
      "250:\tlearn: 3.5586731\ttest: 3.9174187\tbest: 3.9174187 (250)\ttotal: 12.7s\tremaining: 37.9s\n",
      "260:\tlearn: 3.5452883\ttest: 3.9152392\tbest: 3.9145436 (258)\ttotal: 13.2s\tremaining: 37.3s\n",
      "270:\tlearn: 3.5308660\ttest: 3.9151537\tbest: 3.9145436 (258)\ttotal: 13.7s\tremaining: 36.8s\n",
      "280:\tlearn: 3.5132259\ttest: 3.9138350\tbest: 3.9137053 (278)\ttotal: 14.2s\tremaining: 36.4s\n",
      "290:\tlearn: 3.5005071\ttest: 3.9139920\tbest: 3.9137053 (278)\ttotal: 14.7s\tremaining: 35.8s\n",
      "300:\tlearn: 3.4883542\ttest: 3.9172102\tbest: 3.9125326 (291)\ttotal: 15.2s\tremaining: 35.3s\n",
      "310:\tlearn: 3.4755205\ttest: 3.9114373\tbest: 3.9114373 (310)\ttotal: 15.7s\tremaining: 34.8s\n",
      "320:\tlearn: 3.4567450\ttest: 3.9044498\tbest: 3.9041928 (319)\ttotal: 16.2s\tremaining: 34.3s\n",
      "330:\tlearn: 3.4499218\ttest: 3.9043975\tbest: 3.9041707 (322)\ttotal: 16.7s\tremaining: 33.7s\n",
      "340:\tlearn: 3.4381017\ttest: 3.9017779\tbest: 3.9017779 (340)\ttotal: 17.1s\tremaining: 33.1s\n",
      "350:\tlearn: 3.4279987\ttest: 3.9000023\tbest: 3.8986831 (344)\ttotal: 17.7s\tremaining: 32.8s\n",
      "360:\tlearn: 3.4156367\ttest: 3.8992181\tbest: 3.8986831 (344)\ttotal: 18.2s\tremaining: 32.2s\n",
      "370:\tlearn: 3.4090274\ttest: 3.9000412\tbest: 3.8986831 (344)\ttotal: 18.6s\tremaining: 31.6s\n",
      "380:\tlearn: 3.3937553\ttest: 3.8965071\tbest: 3.8956041 (378)\ttotal: 19.2s\tremaining: 31.1s\n",
      "390:\tlearn: 3.3808684\ttest: 3.8932279\tbest: 3.8929307 (387)\ttotal: 19.6s\tremaining: 30.5s\n",
      "400:\tlearn: 3.3727341\ttest: 3.8938765\tbest: 3.8927695 (391)\ttotal: 20.1s\tremaining: 30s\n",
      "410:\tlearn: 3.3598455\ttest: 3.8934632\tbest: 3.8927695 (391)\ttotal: 20.5s\tremaining: 29.4s\n",
      "420:\tlearn: 3.3500431\ttest: 3.8949606\tbest: 3.8927695 (391)\ttotal: 21s\tremaining: 28.9s\n",
      "430:\tlearn: 3.3405465\ttest: 3.8946524\tbest: 3.8927695 (391)\ttotal: 21.5s\tremaining: 28.3s\n",
      "440:\tlearn: 3.3305803\ttest: 3.8958790\tbest: 3.8927695 (391)\ttotal: 22s\tremaining: 27.9s\n",
      "450:\tlearn: 3.3235177\ttest: 3.8951247\tbest: 3.8927695 (391)\ttotal: 22.7s\tremaining: 27.7s\n",
      "460:\tlearn: 3.3094088\ttest: 3.8951551\tbest: 3.8927695 (391)\ttotal: 23.5s\tremaining: 27.5s\n",
      "470:\tlearn: 3.3022690\ttest: 3.8978433\tbest: 3.8927695 (391)\ttotal: 24s\tremaining: 27s\n",
      "480:\tlearn: 3.2917134\ttest: 3.8981180\tbest: 3.8927695 (391)\ttotal: 24.5s\tremaining: 26.5s\n",
      "490:\tlearn: 3.2765643\ttest: 3.8929566\tbest: 3.8927328 (484)\ttotal: 25.1s\tremaining: 26s\n",
      "500:\tlearn: 3.2677040\ttest: 3.8906547\tbest: 3.8904110 (498)\ttotal: 25.6s\tremaining: 25.5s\n",
      "510:\tlearn: 3.2526824\ttest: 3.8862811\tbest: 3.8862811 (510)\ttotal: 26s\tremaining: 24.9s\n",
      "520:\tlearn: 3.2422369\ttest: 3.8875451\tbest: 3.8862811 (510)\ttotal: 26.5s\tremaining: 24.4s\n",
      "530:\tlearn: 3.2295595\ttest: 3.8858515\tbest: 3.8858515 (530)\ttotal: 27.1s\tremaining: 23.9s\n",
      "540:\tlearn: 3.2171635\ttest: 3.8861542\tbest: 3.8855758 (535)\ttotal: 27.6s\tremaining: 23.4s\n",
      "550:\tlearn: 3.2091507\ttest: 3.8860790\tbest: 3.8855758 (535)\ttotal: 28s\tremaining: 22.8s\n",
      "560:\tlearn: 3.1994954\ttest: 3.8878690\tbest: 3.8855758 (535)\ttotal: 28.5s\tremaining: 22.3s\n",
      "570:\tlearn: 3.1868170\ttest: 3.8862970\tbest: 3.8855758 (535)\ttotal: 29s\tremaining: 21.8s\n",
      "580:\tlearn: 3.1778004\ttest: 3.8859851\tbest: 3.8855758 (535)\ttotal: 29.5s\tremaining: 21.2s\n",
      "590:\tlearn: 3.1703181\ttest: 3.8856478\tbest: 3.8855758 (535)\ttotal: 29.9s\tremaining: 20.7s\n",
      "600:\tlearn: 3.1611685\ttest: 3.8852909\tbest: 3.8852339 (599)\ttotal: 30.4s\tremaining: 20.2s\n",
      "610:\tlearn: 3.1554752\ttest: 3.8856173\tbest: 3.8851136 (607)\ttotal: 30.9s\tremaining: 19.7s\n",
      "620:\tlearn: 3.1471020\ttest: 3.8849288\tbest: 3.8843036 (618)\ttotal: 31.4s\tremaining: 19.1s\n",
      "630:\tlearn: 3.1411724\ttest: 3.8858736\tbest: 3.8843036 (618)\ttotal: 31.9s\tremaining: 18.6s\n",
      "640:\tlearn: 3.1305508\ttest: 3.8859632\tbest: 3.8843036 (618)\ttotal: 32.3s\tremaining: 18.1s\n",
      "650:\tlearn: 3.1227282\ttest: 3.8875656\tbest: 3.8843036 (618)\ttotal: 32.8s\tremaining: 17.6s\n",
      "660:\tlearn: 3.1171168\ttest: 3.8880277\tbest: 3.8843036 (618)\ttotal: 33.3s\tremaining: 17.1s\n",
      "670:\tlearn: 3.1095105\ttest: 3.8855839\tbest: 3.8843036 (618)\ttotal: 33.8s\tremaining: 16.6s\n",
      "680:\tlearn: 3.1020348\ttest: 3.8851376\tbest: 3.8843036 (618)\ttotal: 34.3s\tremaining: 16s\n",
      "690:\tlearn: 3.0956106\ttest: 3.8866924\tbest: 3.8843036 (618)\ttotal: 34.8s\tremaining: 15.6s\n",
      "700:\tlearn: 3.0856968\ttest: 3.8867554\tbest: 3.8843036 (618)\ttotal: 35.3s\tremaining: 15s\n",
      "710:\tlearn: 3.0784362\ttest: 3.8881429\tbest: 3.8843036 (618)\ttotal: 35.7s\tremaining: 14.5s\n",
      "720:\tlearn: 3.0689379\ttest: 3.8883705\tbest: 3.8843036 (618)\ttotal: 36.2s\tremaining: 14s\n",
      "730:\tlearn: 3.0628979\ttest: 3.8889678\tbest: 3.8843036 (618)\ttotal: 36.7s\tremaining: 13.5s\n",
      "740:\tlearn: 3.0513286\ttest: 3.8892535\tbest: 3.8843036 (618)\ttotal: 37.2s\tremaining: 13s\n",
      "750:\tlearn: 3.0433046\ttest: 3.8873029\tbest: 3.8843036 (618)\ttotal: 37.7s\tremaining: 12.5s\n",
      "760:\tlearn: 3.0376688\ttest: 3.8873161\tbest: 3.8843036 (618)\ttotal: 38.1s\tremaining: 12s\n",
      "770:\tlearn: 3.0321294\ttest: 3.8877293\tbest: 3.8843036 (618)\ttotal: 38.6s\tremaining: 11.5s\n",
      "780:\tlearn: 3.0213800\ttest: 3.8868337\tbest: 3.8843036 (618)\ttotal: 39.2s\tremaining: 11s\n",
      "790:\tlearn: 3.0101496\ttest: 3.8862059\tbest: 3.8843036 (618)\ttotal: 39.7s\tremaining: 10.5s\n",
      "800:\tlearn: 3.0017031\ttest: 3.8877970\tbest: 3.8843036 (618)\ttotal: 40.2s\tremaining: 9.98s\n",
      "810:\tlearn: 2.9930895\ttest: 3.8881198\tbest: 3.8843036 (618)\ttotal: 40.7s\tremaining: 9.48s\n",
      "820:\tlearn: 2.9831224\ttest: 3.8908039\tbest: 3.8843036 (618)\ttotal: 41.2s\tremaining: 8.97s\n",
      "830:\tlearn: 2.9755712\ttest: 3.8917181\tbest: 3.8843036 (618)\ttotal: 41.6s\tremaining: 8.47s\n",
      "840:\tlearn: 2.9697561\ttest: 3.8923559\tbest: 3.8843036 (618)\ttotal: 42.1s\tremaining: 7.96s\n",
      "850:\tlearn: 2.9614291\ttest: 3.8922928\tbest: 3.8843036 (618)\ttotal: 42.5s\tremaining: 7.45s\n",
      "860:\tlearn: 2.9538215\ttest: 3.8917786\tbest: 3.8843036 (618)\ttotal: 43.1s\tremaining: 6.95s\n",
      "870:\tlearn: 2.9465140\ttest: 3.8928163\tbest: 3.8843036 (618)\ttotal: 43.5s\tremaining: 6.44s\n",
      "880:\tlearn: 2.9405126\ttest: 3.8906941\tbest: 3.8843036 (618)\ttotal: 44s\tremaining: 5.94s\n",
      "890:\tlearn: 2.9303498\ttest: 3.8892378\tbest: 3.8843036 (618)\ttotal: 44.5s\tremaining: 5.44s\n",
      "900:\tlearn: 2.9236614\ttest: 3.8884308\tbest: 3.8843036 (618)\ttotal: 45.1s\tremaining: 4.95s\n",
      "910:\tlearn: 2.9170646\ttest: 3.8888414\tbest: 3.8843036 (618)\ttotal: 45.8s\tremaining: 4.47s\n",
      "920:\tlearn: 2.9099441\ttest: 3.8893086\tbest: 3.8843036 (618)\ttotal: 46.3s\tremaining: 3.97s\n",
      "930:\tlearn: 2.9040996\ttest: 3.8889408\tbest: 3.8843036 (618)\ttotal: 46.8s\tremaining: 3.47s\n",
      "940:\tlearn: 2.8983017\ttest: 3.8892569\tbest: 3.8843036 (618)\ttotal: 47.3s\tremaining: 2.97s\n",
      "950:\tlearn: 2.8910837\ttest: 3.8899095\tbest: 3.8843036 (618)\ttotal: 47.8s\tremaining: 2.46s\n",
      "960:\tlearn: 2.8854538\ttest: 3.8891428\tbest: 3.8843036 (618)\ttotal: 48.4s\tremaining: 1.96s\n",
      "970:\tlearn: 2.8801557\ttest: 3.8903258\tbest: 3.8843036 (618)\ttotal: 48.9s\tremaining: 1.46s\n",
      "980:\tlearn: 2.8755110\ttest: 3.8909599\tbest: 3.8843036 (618)\ttotal: 49.4s\tremaining: 957ms\n",
      "990:\tlearn: 2.8676356\ttest: 3.8915691\tbest: 3.8843036 (618)\ttotal: 49.9s\tremaining: 453ms\n",
      "999:\tlearn: 2.8602041\ttest: 3.8922928\tbest: 3.8843036 (618)\ttotal: 50.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.884303569\n",
      "bestIteration = 618\n",
      "\n",
      "Shrink model to first 619 iterations.\n",
      "R-squared of base model: 0.5159662312506688\n",
      "RMSE of the base model: 3.884\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "#  CatBoost - Baseline\n",
    "# \n",
    "########################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "###############\n",
    "# Specify categorical feature indices\n",
    "categorical_features_indices = [0, 2, 25, 26]\n",
    "\n",
    "\n",
    "# Create the Pool for training data\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=categorical_features_indices)\n",
    "\n",
    "# If you have a validation dataset\n",
    "validation_pool = Pool(data=X_validate, label=y_validate, cat_features=categorical_features_indices)\n",
    "\n",
    "\n",
    "# Instantiate CatBoostRegressor with the best hyperparameters\n",
    "cat_model = CatBoostRegressor()\n",
    "\n",
    "cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=validation_pool,  # Remove this if you don't have a validation set\n",
    "    verbose=10,  # This will print the progress every 10 iterations\n",
    "    plot=True    # This will plot the learning curve (only works in Jupyter notebooks)\n",
    ")\n",
    "\n",
    "predictions = cat_model.predict(X_validate)  # If you used Pool, the data here should not be the Pool object but raw data.\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r2 = r2_score(y_validate, predictions)\n",
    "rmse = mean_squared_error(y_validate, predictions, squared=False)\n",
    "\n",
    "print(f'R-squared of base model: {r2}')\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "\n",
    "########################\n",
    "## Output:\n",
    "########################\n",
    "'''Shrink model to first 619 iterations.\n",
    "R-squared of base model: 0.5159662312506688\n",
    "RMSE of the base model: 3.884'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning -  Optimize Model with Hyperparameter Tuning via Grid Search\n",
    "\n",
    "## CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "#  STANDALONE TUNING  - CatBoost\n",
    "# \n",
    "########################\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Scorer for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "#  RMSE Scorer for GridSearch\n",
    "# \n",
    "########################\n",
    "\n",
    "def rmse_scorer(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Custom scoring function to calculate the negative RMSE (Root Mean Squared Error).\n",
    "\n",
    "    Parameters:\n",
    "        estimator: Scikit-learn estimator object\n",
    "            The model to be evaluated.\n",
    "        X: array-like or pd.DataFrame\n",
    "            Features for prediction.\n",
    "        y: array-like or pd.Series\n",
    "            True target values.\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "            Negative RMSE value.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    # Return negative RMSE for grid search to minimize\n",
    "    return -rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost -  Perform GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 5.4866537\ttotal: 105ms\tremaining: 31.5s\n",
      "1:\tlearn: 5.2917884\ttotal: 212ms\tremaining: 31.6s\n",
      "2:\tlearn: 5.1193445\ttotal: 308ms\tremaining: 30.5s\n",
      "3:\tlearn: 4.9648164\ttotal: 425ms\tremaining: 31.4s\n",
      "4:\tlearn: 4.8209217\ttotal: 529ms\tremaining: 31.2s\n",
      "5:\tlearn: 4.6971158\ttotal: 629ms\tremaining: 30.8s\n",
      "6:\tlearn: 4.5909521\ttotal: 737ms\tremaining: 30.9s\n",
      "7:\tlearn: 4.4976990\ttotal: 840ms\tremaining: 30.7s\n",
      "8:\tlearn: 4.4104866\ttotal: 943ms\tremaining: 30.5s\n",
      "9:\tlearn: 4.3370994\ttotal: 1.05s\tremaining: 30.5s\n",
      "10:\tlearn: 4.2750699\ttotal: 1.15s\tremaining: 30.2s\n",
      "11:\tlearn: 4.2208355\ttotal: 1.26s\tremaining: 30.2s\n",
      "12:\tlearn: 4.1631843\ttotal: 1.37s\tremaining: 30.3s\n",
      "13:\tlearn: 4.1206375\ttotal: 1.48s\tremaining: 30.3s\n",
      "14:\tlearn: 4.0788386\ttotal: 1.59s\tremaining: 30.2s\n",
      "15:\tlearn: 4.0304414\ttotal: 1.7s\tremaining: 30.1s\n",
      "16:\tlearn: 4.0033178\ttotal: 1.8s\tremaining: 29.9s\n",
      "17:\tlearn: 3.9634399\ttotal: 1.91s\tremaining: 29.9s\n",
      "18:\tlearn: 3.9322141\ttotal: 2.01s\tremaining: 29.7s\n",
      "19:\tlearn: 3.9064601\ttotal: 2.12s\tremaining: 29.7s\n",
      "20:\tlearn: 3.8824306\ttotal: 2.22s\tremaining: 29.5s\n",
      "21:\tlearn: 3.8620458\ttotal: 2.33s\tremaining: 29.5s\n",
      "22:\tlearn: 3.8449823\ttotal: 2.44s\tremaining: 29.3s\n",
      "23:\tlearn: 3.8293554\ttotal: 2.54s\tremaining: 29.3s\n",
      "24:\tlearn: 3.8107161\ttotal: 2.65s\tremaining: 29.2s\n",
      "25:\tlearn: 3.7925529\ttotal: 2.76s\tremaining: 29.1s\n",
      "26:\tlearn: 3.7752784\ttotal: 2.87s\tremaining: 29s\n",
      "27:\tlearn: 3.7524891\ttotal: 2.97s\tremaining: 28.9s\n",
      "28:\tlearn: 3.7353073\ttotal: 3.08s\tremaining: 28.8s\n",
      "29:\tlearn: 3.7129706\ttotal: 3.17s\tremaining: 28.6s\n",
      "30:\tlearn: 3.6954709\ttotal: 3.29s\tremaining: 28.5s\n",
      "31:\tlearn: 3.6813876\ttotal: 3.4s\tremaining: 28.4s\n",
      "32:\tlearn: 3.6626835\ttotal: 3.5s\tremaining: 28.3s\n",
      "33:\tlearn: 3.6484448\ttotal: 3.65s\tremaining: 28.6s\n",
      "34:\tlearn: 3.6374223\ttotal: 3.77s\tremaining: 28.5s\n",
      "35:\tlearn: 3.6246407\ttotal: 3.88s\tremaining: 28.4s\n",
      "36:\tlearn: 3.6150735\ttotal: 3.98s\tremaining: 28.3s\n",
      "37:\tlearn: 3.6039268\ttotal: 4.08s\tremaining: 28.2s\n",
      "38:\tlearn: 3.5945673\ttotal: 4.19s\tremaining: 28s\n",
      "39:\tlearn: 3.5842682\ttotal: 4.3s\tremaining: 27.9s\n",
      "40:\tlearn: 3.5676486\ttotal: 4.4s\tremaining: 27.8s\n",
      "41:\tlearn: 3.5604851\ttotal: 4.51s\tremaining: 27.7s\n",
      "42:\tlearn: 3.5493191\ttotal: 4.62s\tremaining: 27.6s\n",
      "43:\tlearn: 3.5417025\ttotal: 4.76s\tremaining: 27.7s\n",
      "44:\tlearn: 3.5349745\ttotal: 4.87s\tremaining: 27.6s\n",
      "45:\tlearn: 3.5298669\ttotal: 4.99s\tremaining: 27.5s\n",
      "46:\tlearn: 3.5179560\ttotal: 5.1s\tremaining: 27.5s\n",
      "47:\tlearn: 3.5116438\ttotal: 5.21s\tremaining: 27.3s\n",
      "48:\tlearn: 3.4990451\ttotal: 5.31s\tremaining: 27.2s\n",
      "49:\tlearn: 3.4874441\ttotal: 5.42s\tremaining: 27.1s\n",
      "50:\tlearn: 3.4808833\ttotal: 5.52s\tremaining: 27s\n",
      "51:\tlearn: 3.4720599\ttotal: 5.67s\tremaining: 27s\n",
      "52:\tlearn: 3.4663144\ttotal: 5.78s\tremaining: 26.9s\n",
      "53:\tlearn: 3.4549813\ttotal: 5.88s\tremaining: 26.8s\n",
      "54:\tlearn: 3.4521277\ttotal: 5.99s\tremaining: 26.7s\n",
      "55:\tlearn: 3.4432272\ttotal: 6.1s\tremaining: 26.6s\n",
      "56:\tlearn: 3.4378980\ttotal: 6.2s\tremaining: 26.4s\n",
      "57:\tlearn: 3.4234772\ttotal: 6.3s\tremaining: 26.3s\n",
      "58:\tlearn: 3.4197051\ttotal: 6.41s\tremaining: 26.2s\n",
      "59:\tlearn: 3.4168320\ttotal: 6.51s\tremaining: 26.1s\n",
      "60:\tlearn: 3.4097646\ttotal: 6.62s\tremaining: 25.9s\n",
      "61:\tlearn: 3.4051485\ttotal: 6.72s\tremaining: 25.8s\n",
      "62:\tlearn: 3.4011297\ttotal: 6.82s\tremaining: 25.7s\n",
      "63:\tlearn: 3.3946877\ttotal: 6.93s\tremaining: 25.6s\n",
      "64:\tlearn: 3.3858244\ttotal: 7.04s\tremaining: 25.4s\n",
      "65:\tlearn: 3.3771371\ttotal: 7.14s\tremaining: 25.3s\n",
      "66:\tlearn: 3.3698572\ttotal: 7.24s\tremaining: 25.2s\n",
      "67:\tlearn: 3.3645972\ttotal: 7.35s\tremaining: 25.1s\n",
      "68:\tlearn: 3.3605349\ttotal: 7.46s\tremaining: 25s\n",
      "69:\tlearn: 3.3570129\ttotal: 7.55s\tremaining: 24.8s\n",
      "70:\tlearn: 3.3513268\ttotal: 7.66s\tremaining: 24.7s\n",
      "71:\tlearn: 3.3502878\ttotal: 7.69s\tremaining: 24.4s\n",
      "72:\tlearn: 3.3414794\ttotal: 7.8s\tremaining: 24.3s\n",
      "73:\tlearn: 3.3386786\ttotal: 7.91s\tremaining: 24.1s\n",
      "74:\tlearn: 3.3282365\ttotal: 8.03s\tremaining: 24.1s\n",
      "75:\tlearn: 3.3235570\ttotal: 8.19s\tremaining: 24.1s\n",
      "76:\tlearn: 3.3177171\ttotal: 8.34s\tremaining: 24.1s\n",
      "77:\tlearn: 3.3134131\ttotal: 8.48s\tremaining: 24.1s\n",
      "78:\tlearn: 3.3072174\ttotal: 8.59s\tremaining: 24s\n",
      "79:\tlearn: 3.3016059\ttotal: 8.71s\tremaining: 23.9s\n",
      "80:\tlearn: 3.3000278\ttotal: 8.83s\tremaining: 23.9s\n",
      "81:\tlearn: 3.2959020\ttotal: 8.94s\tremaining: 23.8s\n",
      "82:\tlearn: 3.2880628\ttotal: 9.05s\tremaining: 23.7s\n",
      "83:\tlearn: 3.2876095\ttotal: 9.1s\tremaining: 23.4s\n",
      "84:\tlearn: 3.2820727\ttotal: 9.21s\tremaining: 23.3s\n",
      "85:\tlearn: 3.2803460\ttotal: 9.32s\tremaining: 23.2s\n",
      "86:\tlearn: 3.2747132\ttotal: 9.44s\tremaining: 23.1s\n",
      "87:\tlearn: 3.2706676\ttotal: 9.56s\tremaining: 23s\n",
      "88:\tlearn: 3.2659149\ttotal: 9.68s\tremaining: 22.9s\n",
      "89:\tlearn: 3.2641293\ttotal: 9.79s\tremaining: 22.8s\n",
      "90:\tlearn: 3.2602318\ttotal: 9.89s\tremaining: 22.7s\n",
      "91:\tlearn: 3.2500673\ttotal: 10s\tremaining: 22.6s\n",
      "92:\tlearn: 3.2415111\ttotal: 10.1s\tremaining: 22.5s\n",
      "93:\tlearn: 3.2384640\ttotal: 10.2s\tremaining: 22.4s\n",
      "94:\tlearn: 3.2359802\ttotal: 10.3s\tremaining: 22.3s\n",
      "95:\tlearn: 3.2309603\ttotal: 10.4s\tremaining: 22.2s\n",
      "96:\tlearn: 3.2223780\ttotal: 10.6s\tremaining: 22.1s\n",
      "97:\tlearn: 3.2195373\ttotal: 10.7s\tremaining: 22s\n",
      "98:\tlearn: 3.2160753\ttotal: 10.8s\tremaining: 21.9s\n",
      "99:\tlearn: 3.2154962\ttotal: 10.8s\tremaining: 21.6s\n",
      "100:\tlearn: 3.2125047\ttotal: 10.9s\tremaining: 21.5s\n",
      "101:\tlearn: 3.2102084\ttotal: 11s\tremaining: 21.4s\n",
      "102:\tlearn: 3.2079942\ttotal: 11.2s\tremaining: 21.3s\n",
      "103:\tlearn: 3.2045133\ttotal: 11.3s\tremaining: 21.2s\n",
      "104:\tlearn: 3.2016157\ttotal: 11.4s\tremaining: 21.1s\n",
      "105:\tlearn: 3.1997447\ttotal: 11.5s\tremaining: 21.1s\n",
      "106:\tlearn: 3.1974275\ttotal: 11.6s\tremaining: 21s\n",
      "107:\tlearn: 3.1917365\ttotal: 11.7s\tremaining: 20.9s\n",
      "108:\tlearn: 3.1885718\ttotal: 11.9s\tremaining: 20.8s\n",
      "109:\tlearn: 3.1849838\ttotal: 12s\tremaining: 20.7s\n",
      "110:\tlearn: 3.1830846\ttotal: 12.1s\tremaining: 20.6s\n",
      "111:\tlearn: 3.1791378\ttotal: 12.2s\tremaining: 20.5s\n",
      "112:\tlearn: 3.1740197\ttotal: 12.3s\tremaining: 20.4s\n",
      "113:\tlearn: 3.1731160\ttotal: 12.5s\tremaining: 20.3s\n",
      "114:\tlearn: 3.1708589\ttotal: 12.6s\tremaining: 20.2s\n",
      "115:\tlearn: 3.1695872\ttotal: 12.7s\tremaining: 20.1s\n",
      "116:\tlearn: 3.1617481\ttotal: 12.8s\tremaining: 20.1s\n",
      "117:\tlearn: 3.1596318\ttotal: 13s\tremaining: 20s\n",
      "118:\tlearn: 3.1575109\ttotal: 13.1s\tremaining: 19.9s\n",
      "119:\tlearn: 3.1565151\ttotal: 13.2s\tremaining: 19.8s\n",
      "120:\tlearn: 3.1549568\ttotal: 13.3s\tremaining: 19.7s\n",
      "121:\tlearn: 3.1515005\ttotal: 13.4s\tremaining: 19.6s\n",
      "122:\tlearn: 3.1497120\ttotal: 13.6s\tremaining: 19.5s\n",
      "123:\tlearn: 3.1463016\ttotal: 13.7s\tremaining: 19.4s\n",
      "124:\tlearn: 3.1427309\ttotal: 13.8s\tremaining: 19.3s\n",
      "125:\tlearn: 3.1414926\ttotal: 13.9s\tremaining: 19.2s\n",
      "126:\tlearn: 3.1387348\ttotal: 14s\tremaining: 19.1s\n",
      "127:\tlearn: 3.1353547\ttotal: 14.2s\tremaining: 19s\n",
      "128:\tlearn: 3.1316735\ttotal: 14.3s\tremaining: 18.9s\n",
      "129:\tlearn: 3.1302542\ttotal: 14.4s\tremaining: 18.8s\n",
      "130:\tlearn: 3.1277833\ttotal: 14.5s\tremaining: 18.7s\n",
      "131:\tlearn: 3.1219385\ttotal: 14.6s\tremaining: 18.6s\n",
      "132:\tlearn: 3.1213632\ttotal: 14.7s\tremaining: 18.5s\n",
      "133:\tlearn: 3.1185249\ttotal: 14.8s\tremaining: 18.4s\n",
      "134:\tlearn: 3.1157526\ttotal: 14.9s\tremaining: 18.3s\n",
      "135:\tlearn: 3.1117978\ttotal: 15.1s\tremaining: 18.2s\n",
      "136:\tlearn: 3.1089658\ttotal: 15.2s\tremaining: 18s\n",
      "137:\tlearn: 3.1048787\ttotal: 15.3s\tremaining: 17.9s\n",
      "138:\tlearn: 3.1041893\ttotal: 15.4s\tremaining: 17.8s\n",
      "139:\tlearn: 3.1002006\ttotal: 15.5s\tremaining: 17.7s\n",
      "140:\tlearn: 3.0976805\ttotal: 15.6s\tremaining: 17.6s\n",
      "141:\tlearn: 3.0968357\ttotal: 15.7s\tremaining: 17.5s\n",
      "142:\tlearn: 3.0957542\ttotal: 15.8s\tremaining: 17.4s\n",
      "143:\tlearn: 3.0928126\ttotal: 15.9s\tremaining: 17.2s\n",
      "144:\tlearn: 3.0895731\ttotal: 16s\tremaining: 17.1s\n",
      "145:\tlearn: 3.0886395\ttotal: 16.1s\tremaining: 17s\n",
      "146:\tlearn: 3.0843006\ttotal: 16.2s\tremaining: 16.9s\n",
      "147:\tlearn: 3.0833734\ttotal: 16.3s\tremaining: 16.8s\n",
      "148:\tlearn: 3.0826749\ttotal: 16.4s\tremaining: 16.7s\n",
      "149:\tlearn: 3.0771249\ttotal: 16.5s\tremaining: 16.5s\n",
      "150:\tlearn: 3.0749158\ttotal: 16.6s\tremaining: 16.4s\n",
      "151:\tlearn: 3.0708307\ttotal: 16.8s\tremaining: 16.3s\n",
      "152:\tlearn: 3.0671502\ttotal: 16.9s\tremaining: 16.2s\n",
      "153:\tlearn: 3.0643598\ttotal: 17s\tremaining: 16.1s\n",
      "154:\tlearn: 3.0536739\ttotal: 17.1s\tremaining: 16s\n",
      "155:\tlearn: 3.0522279\ttotal: 17.2s\tremaining: 15.9s\n",
      "156:\tlearn: 3.0484894\ttotal: 17.3s\tremaining: 15.7s\n",
      "157:\tlearn: 3.0438902\ttotal: 17.4s\tremaining: 15.6s\n",
      "158:\tlearn: 3.0413836\ttotal: 17.5s\tremaining: 15.5s\n",
      "159:\tlearn: 3.0394255\ttotal: 17.6s\tremaining: 15.4s\n",
      "160:\tlearn: 3.0354503\ttotal: 17.7s\tremaining: 15.3s\n",
      "161:\tlearn: 3.0306448\ttotal: 17.8s\tremaining: 15.2s\n",
      "162:\tlearn: 3.0290274\ttotal: 17.9s\tremaining: 15.1s\n",
      "163:\tlearn: 3.0270080\ttotal: 18s\tremaining: 15s\n",
      "164:\tlearn: 3.0255478\ttotal: 18.2s\tremaining: 14.9s\n",
      "165:\tlearn: 3.0228711\ttotal: 18.3s\tremaining: 14.7s\n",
      "166:\tlearn: 3.0222298\ttotal: 18.4s\tremaining: 14.6s\n",
      "167:\tlearn: 3.0155942\ttotal: 18.5s\tremaining: 14.5s\n",
      "168:\tlearn: 3.0116801\ttotal: 18.6s\tremaining: 14.4s\n",
      "169:\tlearn: 3.0096690\ttotal: 18.7s\tremaining: 14.3s\n",
      "170:\tlearn: 3.0066457\ttotal: 18.8s\tremaining: 14.2s\n",
      "171:\tlearn: 3.0024899\ttotal: 18.9s\tremaining: 14.1s\n",
      "172:\tlearn: 3.0022455\ttotal: 19.1s\tremaining: 14s\n",
      "173:\tlearn: 2.9998640\ttotal: 19.2s\tremaining: 13.9s\n",
      "174:\tlearn: 2.9976106\ttotal: 19.3s\tremaining: 13.8s\n",
      "175:\tlearn: 2.9923199\ttotal: 19.4s\tremaining: 13.7s\n",
      "176:\tlearn: 2.9868941\ttotal: 19.6s\tremaining: 13.6s\n",
      "177:\tlearn: 2.9853266\ttotal: 19.7s\tremaining: 13.5s\n",
      "178:\tlearn: 2.9799597\ttotal: 19.8s\tremaining: 13.4s\n",
      "179:\tlearn: 2.9776186\ttotal: 19.9s\tremaining: 13.3s\n",
      "180:\tlearn: 2.9746372\ttotal: 20s\tremaining: 13.2s\n",
      "181:\tlearn: 2.9724949\ttotal: 20.1s\tremaining: 13.1s\n",
      "182:\tlearn: 2.9690035\ttotal: 20.2s\tremaining: 12.9s\n",
      "183:\tlearn: 2.9662536\ttotal: 20.4s\tremaining: 12.8s\n",
      "184:\tlearn: 2.9651498\ttotal: 20.5s\tremaining: 12.7s\n",
      "185:\tlearn: 2.9619247\ttotal: 20.6s\tremaining: 12.6s\n",
      "186:\tlearn: 2.9583848\ttotal: 20.7s\tremaining: 12.5s\n",
      "187:\tlearn: 2.9532971\ttotal: 20.8s\tremaining: 12.4s\n",
      "188:\tlearn: 2.9498355\ttotal: 20.9s\tremaining: 12.3s\n",
      "189:\tlearn: 2.9470131\ttotal: 21s\tremaining: 12.2s\n",
      "190:\tlearn: 2.9442846\ttotal: 21.1s\tremaining: 12s\n",
      "191:\tlearn: 2.9419239\ttotal: 21.2s\tremaining: 11.9s\n",
      "192:\tlearn: 2.9400562\ttotal: 21.3s\tremaining: 11.8s\n",
      "193:\tlearn: 2.9366446\ttotal: 21.4s\tremaining: 11.7s\n",
      "194:\tlearn: 2.9318067\ttotal: 21.5s\tremaining: 11.6s\n",
      "195:\tlearn: 2.9316746\ttotal: 21.6s\tremaining: 11.5s\n",
      "196:\tlearn: 2.9260375\ttotal: 21.8s\tremaining: 11.4s\n",
      "197:\tlearn: 2.9227197\ttotal: 21.9s\tremaining: 11.3s\n",
      "198:\tlearn: 2.9198177\ttotal: 22s\tremaining: 11.1s\n",
      "199:\tlearn: 2.9127357\ttotal: 22.1s\tremaining: 11s\n",
      "200:\tlearn: 2.9091903\ttotal: 22.2s\tremaining: 10.9s\n",
      "201:\tlearn: 2.9028515\ttotal: 22.3s\tremaining: 10.8s\n",
      "202:\tlearn: 2.9007691\ttotal: 22.4s\tremaining: 10.7s\n",
      "203:\tlearn: 2.8983917\ttotal: 22.5s\tremaining: 10.6s\n",
      "204:\tlearn: 2.8961665\ttotal: 22.6s\tremaining: 10.5s\n",
      "205:\tlearn: 2.8938632\ttotal: 22.7s\tremaining: 10.4s\n",
      "206:\tlearn: 2.8924804\ttotal: 22.8s\tremaining: 10.3s\n",
      "207:\tlearn: 2.8910690\ttotal: 22.9s\tremaining: 10.1s\n",
      "208:\tlearn: 2.8877928\ttotal: 23s\tremaining: 10s\n",
      "209:\tlearn: 2.8858363\ttotal: 23.2s\tremaining: 9.92s\n",
      "210:\tlearn: 2.8850277\ttotal: 23.3s\tremaining: 9.81s\n",
      "211:\tlearn: 2.8826909\ttotal: 23.4s\tremaining: 9.7s\n",
      "212:\tlearn: 2.8790972\ttotal: 23.5s\tremaining: 9.59s\n",
      "213:\tlearn: 2.8755948\ttotal: 23.6s\tremaining: 9.48s\n",
      "214:\tlearn: 2.8716898\ttotal: 23.7s\tremaining: 9.36s\n",
      "215:\tlearn: 2.8692368\ttotal: 23.8s\tremaining: 9.25s\n",
      "216:\tlearn: 2.8664137\ttotal: 23.9s\tremaining: 9.14s\n",
      "217:\tlearn: 2.8650510\ttotal: 24s\tremaining: 9.03s\n",
      "218:\tlearn: 2.8615526\ttotal: 24.1s\tremaining: 8.91s\n",
      "219:\tlearn: 2.8565030\ttotal: 24.2s\tremaining: 8.8s\n",
      "220:\tlearn: 2.8511513\ttotal: 24.3s\tremaining: 8.69s\n",
      "221:\tlearn: 2.8495554\ttotal: 24.4s\tremaining: 8.58s\n",
      "222:\tlearn: 2.8476907\ttotal: 24.5s\tremaining: 8.47s\n",
      "223:\tlearn: 2.8454198\ttotal: 24.6s\tremaining: 8.36s\n",
      "224:\tlearn: 2.8389061\ttotal: 24.7s\tremaining: 8.25s\n",
      "225:\tlearn: 2.8359717\ttotal: 24.8s\tremaining: 8.13s\n",
      "226:\tlearn: 2.8332435\ttotal: 25s\tremaining: 8.03s\n",
      "227:\tlearn: 2.8284014\ttotal: 25.1s\tremaining: 7.91s\n",
      "228:\tlearn: 2.8238835\ttotal: 25.2s\tremaining: 7.8s\n",
      "229:\tlearn: 2.8222342\ttotal: 25.3s\tremaining: 7.69s\n",
      "230:\tlearn: 2.8184154\ttotal: 25.4s\tremaining: 7.58s\n",
      "231:\tlearn: 2.8129220\ttotal: 25.5s\tremaining: 7.47s\n",
      "232:\tlearn: 2.8117028\ttotal: 25.6s\tremaining: 7.36s\n",
      "233:\tlearn: 2.8096319\ttotal: 25.7s\tremaining: 7.25s\n",
      "234:\tlearn: 2.8089923\ttotal: 25.8s\tremaining: 7.13s\n",
      "235:\tlearn: 2.8048215\ttotal: 25.9s\tremaining: 7.02s\n",
      "236:\tlearn: 2.8032039\ttotal: 26s\tremaining: 6.91s\n",
      "237:\tlearn: 2.8008255\ttotal: 26.1s\tremaining: 6.8s\n",
      "238:\tlearn: 2.7967548\ttotal: 26.2s\tremaining: 6.69s\n",
      "239:\tlearn: 2.7965049\ttotal: 26.3s\tremaining: 6.58s\n",
      "240:\tlearn: 2.7939817\ttotal: 26.4s\tremaining: 6.47s\n",
      "241:\tlearn: 2.7920843\ttotal: 26.5s\tremaining: 6.36s\n",
      "242:\tlearn: 2.7901515\ttotal: 26.6s\tremaining: 6.25s\n",
      "243:\tlearn: 2.7869906\ttotal: 26.7s\tremaining: 6.14s\n",
      "244:\tlearn: 2.7798487\ttotal: 26.9s\tremaining: 6.03s\n",
      "245:\tlearn: 2.7742296\ttotal: 27s\tremaining: 5.92s\n",
      "246:\tlearn: 2.7709725\ttotal: 27.1s\tremaining: 5.8s\n",
      "247:\tlearn: 2.7686673\ttotal: 27.2s\tremaining: 5.69s\n",
      "248:\tlearn: 2.7659592\ttotal: 27.3s\tremaining: 5.58s\n",
      "249:\tlearn: 2.7640491\ttotal: 27.4s\tremaining: 5.47s\n",
      "250:\tlearn: 2.7588619\ttotal: 27.5s\tremaining: 5.36s\n",
      "251:\tlearn: 2.7551702\ttotal: 27.6s\tremaining: 5.25s\n",
      "252:\tlearn: 2.7524932\ttotal: 27.7s\tremaining: 5.14s\n",
      "253:\tlearn: 2.7467369\ttotal: 27.8s\tremaining: 5.03s\n",
      "254:\tlearn: 2.7429900\ttotal: 27.9s\tremaining: 4.92s\n",
      "255:\tlearn: 2.7359185\ttotal: 28s\tremaining: 4.81s\n",
      "256:\tlearn: 2.7333894\ttotal: 28.1s\tremaining: 4.7s\n",
      "257:\tlearn: 2.7292401\ttotal: 28.2s\tremaining: 4.59s\n",
      "258:\tlearn: 2.7282490\ttotal: 28.3s\tremaining: 4.48s\n",
      "259:\tlearn: 2.7279693\ttotal: 28.4s\tremaining: 4.37s\n",
      "260:\tlearn: 2.7262179\ttotal: 28.5s\tremaining: 4.26s\n",
      "261:\tlearn: 2.7217720\ttotal: 28.6s\tremaining: 4.15s\n",
      "262:\tlearn: 2.7204121\ttotal: 28.7s\tremaining: 4.04s\n",
      "263:\tlearn: 2.7180453\ttotal: 28.8s\tremaining: 3.93s\n",
      "264:\tlearn: 2.7165522\ttotal: 28.9s\tremaining: 3.82s\n",
      "265:\tlearn: 2.7121848\ttotal: 29s\tremaining: 3.71s\n",
      "266:\tlearn: 2.7070888\ttotal: 29.1s\tremaining: 3.6s\n",
      "267:\tlearn: 2.7061870\ttotal: 29.3s\tremaining: 3.49s\n",
      "268:\tlearn: 2.7032274\ttotal: 29.4s\tremaining: 3.38s\n",
      "269:\tlearn: 2.7022943\ttotal: 29.5s\tremaining: 3.27s\n",
      "270:\tlearn: 2.7013186\ttotal: 29.6s\tremaining: 3.17s\n",
      "271:\tlearn: 2.7011740\ttotal: 29.7s\tremaining: 3.06s\n",
      "272:\tlearn: 2.6977849\ttotal: 29.8s\tremaining: 2.95s\n",
      "273:\tlearn: 2.6957574\ttotal: 29.9s\tremaining: 2.84s\n",
      "274:\tlearn: 2.6934554\ttotal: 30s\tremaining: 2.73s\n",
      "275:\tlearn: 2.6923993\ttotal: 30.1s\tremaining: 2.62s\n",
      "276:\tlearn: 2.6879825\ttotal: 30.2s\tremaining: 2.51s\n",
      "277:\tlearn: 2.6839045\ttotal: 30.3s\tremaining: 2.4s\n",
      "278:\tlearn: 2.6787837\ttotal: 30.4s\tremaining: 2.29s\n",
      "279:\tlearn: 2.6784669\ttotal: 30.5s\tremaining: 2.18s\n",
      "280:\tlearn: 2.6722549\ttotal: 30.6s\tremaining: 2.07s\n",
      "281:\tlearn: 2.6708369\ttotal: 30.8s\tremaining: 1.96s\n",
      "282:\tlearn: 2.6664160\ttotal: 30.9s\tremaining: 1.85s\n",
      "283:\tlearn: 2.6660538\ttotal: 31s\tremaining: 1.74s\n",
      "284:\tlearn: 2.6647581\ttotal: 31.1s\tremaining: 1.64s\n",
      "285:\tlearn: 2.6636968\ttotal: 31.2s\tremaining: 1.53s\n",
      "286:\tlearn: 2.6593935\ttotal: 31.3s\tremaining: 1.42s\n",
      "287:\tlearn: 2.6555730\ttotal: 31.4s\tremaining: 1.31s\n",
      "288:\tlearn: 2.6522903\ttotal: 31.5s\tremaining: 1.2s\n",
      "289:\tlearn: 2.6510544\ttotal: 31.6s\tremaining: 1.09s\n",
      "290:\tlearn: 2.6507450\ttotal: 31.7s\tremaining: 981ms\n",
      "291:\tlearn: 2.6471204\ttotal: 31.8s\tremaining: 872ms\n",
      "292:\tlearn: 2.6453888\ttotal: 31.9s\tremaining: 763ms\n",
      "293:\tlearn: 2.6415542\ttotal: 32s\tremaining: 654ms\n",
      "294:\tlearn: 2.6380828\ttotal: 32.2s\tremaining: 545ms\n",
      "295:\tlearn: 2.6366309\ttotal: 32.3s\tremaining: 436ms\n",
      "296:\tlearn: 2.6342640\ttotal: 32.4s\tremaining: 327ms\n",
      "297:\tlearn: 2.6339969\ttotal: 32.5s\tremaining: 218ms\n",
      "298:\tlearn: 2.6323842\ttotal: 32.6s\tremaining: 109ms\n",
      "299:\tlearn: 2.6316351\ttotal: 32.7s\tremaining: 0us\n",
      "Best hyperparameters found:\n",
      "{'depth': 10, 'iterations': 300, 'learning_rate': 0.1}\n",
      "Best RMSE score: 3.834154628241867\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "\n",
    "categorical_features_indices =[0, 2, 25, 26]\n",
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300],      # Number of boosting iterations\n",
    "    'depth': [6, 8, 10],                # Depth of trees\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate  \n",
    "    }\n",
    "\n",
    "# Create a CatBoostRegressor model\n",
    "catboost_model = CatBoostRegressor()\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, cv=5, scoring=rmse_scorer, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train, cat_features=categorical_features_indices)\n",
    "\n",
    "# Print the best hyperparameters and corresponding MSE score\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best RMSE score:\", -grid_search.best_score_)\n",
    "\n",
    "# Get the best trained model\n",
    "best_catboost_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "validation_predictions = best_catboost_model.predict(X_validate)\n",
    "\n",
    "########################\n",
    "## Output:\n",
    "########################\n",
    "'''Best hyperparameters found:\n",
    "{'depth': 10, 'iterations': 300, 'learning_rate': 0.1}\n",
    "Best RMSE score: 3.834154628241867'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost - Train Model on Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7798d6343b384d3e8a69e864ce27d092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 5.4924213\ttest: 5.3998622\tbest: 5.3998622 (0)\ttotal: 212ms\tremaining: 42.2s\n",
      "10:\tlearn: 4.3908041\ttest: 4.3521760\tbest: 4.3521760 (10)\ttotal: 909ms\tremaining: 15.6s\n",
      "20:\tlearn: 4.0655363\ttest: 4.1091377\tbest: 4.1091377 (20)\ttotal: 1.63s\tremaining: 13.9s\n",
      "30:\tlearn: 3.9183661\ttest: 4.0236519\tbest: 4.0236519 (30)\ttotal: 2.37s\tremaining: 12.9s\n",
      "40:\tlearn: 3.8108284\ttest: 3.9646639\tbest: 3.9646639 (40)\ttotal: 3.17s\tremaining: 12.3s\n",
      "50:\tlearn: 3.7525718\ttest: 3.9464708\tbest: 3.9464708 (50)\ttotal: 3.94s\tremaining: 11.5s\n",
      "60:\tlearn: 3.7046461\ttest: 3.9291717\tbest: 3.9291717 (60)\ttotal: 4.67s\tremaining: 10.6s\n",
      "70:\tlearn: 3.6728938\ttest: 3.9209391\tbest: 3.9209391 (70)\ttotal: 5.37s\tremaining: 9.76s\n",
      "80:\tlearn: 3.6356634\ttest: 3.9115113\tbest: 3.9115113 (80)\ttotal: 6.06s\tremaining: 8.9s\n",
      "90:\tlearn: 3.5977834\ttest: 3.9060306\tbest: 3.9060306 (90)\ttotal: 6.8s\tremaining: 8.14s\n",
      "100:\tlearn: 3.5684941\ttest: 3.9048493\tbest: 3.9048493 (100)\ttotal: 7.58s\tremaining: 7.42s\n",
      "110:\tlearn: 3.5428223\ttest: 3.8949711\tbest: 3.8949711 (110)\ttotal: 8.25s\tremaining: 6.62s\n",
      "120:\tlearn: 3.5168289\ttest: 3.8926423\tbest: 3.8920255 (116)\ttotal: 9s\tremaining: 5.87s\n",
      "130:\tlearn: 3.4980809\ttest: 3.8902582\tbest: 3.8893182 (128)\ttotal: 9.78s\tremaining: 5.15s\n",
      "140:\tlearn: 3.4717591\ttest: 3.8905800\tbest: 3.8893182 (128)\ttotal: 10.6s\tremaining: 4.43s\n",
      "150:\tlearn: 3.4460989\ttest: 3.8925059\tbest: 3.8893182 (128)\ttotal: 11.4s\tremaining: 3.69s\n",
      "160:\tlearn: 3.4250914\ttest: 3.8907121\tbest: 3.8893182 (128)\ttotal: 12.2s\tremaining: 2.95s\n",
      "170:\tlearn: 3.3992302\ttest: 3.8839331\tbest: 3.8839331 (170)\ttotal: 13.1s\tremaining: 2.21s\n",
      "180:\tlearn: 3.3660098\ttest: 3.8723351\tbest: 3.8723351 (180)\ttotal: 13.8s\tremaining: 1.44s\n",
      "190:\tlearn: 3.3296603\ttest: 3.8596909\tbest: 3.8596791 (188)\ttotal: 14.5s\tremaining: 683ms\n",
      "199:\tlearn: 3.3096737\ttest: 3.8557555\tbest: 3.8550405 (195)\ttotal: 15.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.855040513\n",
      "bestIteration = 195\n",
      "\n",
      "Shrink model to first 196 iterations.\n",
      "R-squared of base model: 0.5232318591945018\n",
      "RMSE of the base model: 3.855\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "#  OPTIMIZED - CatBoost\n",
    "# \n",
    "########################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "###############\n",
    "# Specify categorical feature indices\n",
    "categorical_features_indices = [0, 2, 25, 26]\n",
    "\n",
    "\n",
    "# Create the Pool for training data\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=categorical_features_indices)\n",
    "\n",
    "# If you have a validation dataset\n",
    "validation_pool = Pool(data=X_validate, label=y_validate, cat_features=categorical_features_indices)\n",
    "\n",
    "#########\n",
    "# Best hyperparameters found (after hyperparameter tuning)\n",
    "best_params = {'depth': 8, 'iterations': 200, 'learning_rate': 0.1}\n",
    "\n",
    "# Instantiate CatBoostRegressor with the best hyperparameters\n",
    "cat_model = CatBoostRegressor(**best_params)\n",
    "\n",
    "cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=validation_pool,  # Remove this if you don't have a validation set\n",
    "    verbose=10,  # This will print the progress every 10 iterations\n",
    "    plot=True    # This will plot the learning curve (only works in Jupyter notebooks)\n",
    ")\n",
    "\n",
    "\n",
    "predictions = cat_model.predict(X_validate)  # If you used Pool, the data here should not be the Pool object but raw data.\n",
    "\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r2 = r2_score(y_validate, predictions)\n",
    "rmse = mean_squared_error(y_validate, predictions, squared=False)\n",
    "\n",
    "\n",
    "print(f'R-squared of base model: {r2}')\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "\n",
    "\n",
    "########################\n",
    "## Output:\n",
    "########################\n",
    "'''bestTest = 3.855040513\n",
    "bestIteration = 195\n",
    "\n",
    "Shrink model to first 196 iterations.\n",
    "R-squared of base model: 0.5232318591945018\n",
    "RMSE of the base model: 3.855'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS - Random Forest - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0WJ'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\pandas\\core\\generic.py\", line 2084, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: '0WJ'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamie\\OneDrive - Lepard & Lepard\\Data Science\\LighthouseLabs\\Python_Projects\\Prolonged_LOS_Project\\_src\\06b.FullSope_Model_CatBoost.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/06b.FullSope_Model_CatBoost.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m rf_model \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/06b.FullSope_Model_CatBoost.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mrf_model, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39mrmse_scorer, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/06b.FullSope_Model_CatBoost.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/06b.FullSope_Model_CatBoost.ipynb#X40sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest hyperparameters found:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamie/OneDrive%20-%20Lepard%20%26%20Lepard/Data%20Science/LighthouseLabs/Python_Projects/Prolonged_LOS_Project/_src/06b.FullSope_Model_CatBoost.ipynb#X40sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '0WJ'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]    }\n",
    "\n",
    "categorical_transform = Pipeline([('one-hot-encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))])\n",
    "preprocessing_df = ColumnTransformer([('categorical', categorical_transform, COLS_TO_CAST)])\n",
    "\n",
    "# X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring=rmse_scorer, n_jobs=-1, error_score='raise')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best RMSE score:\", -grid_search.best_score_)\n",
    "\n",
    "best_randomforest_model = grid_search.best_estimator_\n",
    "validation_predictions = best_randomforest_model.predict(X_validate)\n",
    "\n",
    "r2 = r2_score(y_validate, validation_predictions)\n",
    "rmse = mean_squared_error(y_validate, validation_predictions, squared=False)\n",
    "\n",
    "print(f'R-squared of the best model: {r2}')\n",
    "print(f\"RMSE of the best model: {rmse:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
