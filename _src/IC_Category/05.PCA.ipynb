{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt # NOTE: This was tested with matplotlib v. 2.1.0\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91862 entries, 0 to 102290\n",
      "Data columns (total 64 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   op_id              91862 non-null  int64  \n",
      " 1   subject_id         91862 non-null  int64  \n",
      " 2   hadm_id            91862 non-null  int64  \n",
      " 3   opdate             91862 non-null  int64  \n",
      " 4   age                91862 non-null  int64  \n",
      " 5   sex                91862 non-null  object \n",
      " 6   weight             90910 non-null  float64\n",
      " 7   height             91326 non-null  float64\n",
      " 8   race               91862 non-null  object \n",
      " 9   asa                89532 non-null  float64\n",
      " 10  emop               91862 non-null  int64  \n",
      " 11  department         91862 non-null  object \n",
      " 12  antype             91862 non-null  object \n",
      " 13  icd10_pcs          91862 non-null  object \n",
      " 14  category_desc      91862 non-null  object \n",
      " 15  desc_short         91862 non-null  object \n",
      " 16  category_id        91862 non-null  object \n",
      " 17  orin_time          91862 non-null  int64  \n",
      " 18  orout_time         91862 non-null  int64  \n",
      " 19  opstart_time       91854 non-null  float64\n",
      " 20  opend_time         91854 non-null  float64\n",
      " 21  admission_time     91862 non-null  int64  \n",
      " 22  discharge_time     91862 non-null  int64  \n",
      " 23  anstart_time       91823 non-null  float64\n",
      " 24  anend_time         91612 non-null  float64\n",
      " 25  cpbon_time         2153 non-null   float64\n",
      " 26  cpboff_time        2153 non-null   float64\n",
      " 27  icuin_time         11210 non-null  float64\n",
      " 28  icuout_time        11210 non-null  float64\n",
      " 29  inhosp_death_time  969 non-null    float64\n",
      " 30  subject_id_y       91836 non-null  float64\n",
      " 31  chart_time_x       91836 non-null  float64\n",
      " 32  art_dbp            26232 non-null  float64\n",
      " 33  art_mbp            89504 non-null  float64\n",
      " 34  art_sbp            89497 non-null  float64\n",
      " 35  bt                 89479 non-null  float64\n",
      " 36  cvp                89248 non-null  float64\n",
      " 37  hr                 89515 non-null  float64\n",
      " 38  pip                89519 non-null  float64\n",
      " 39  pmean              89508 non-null  float64\n",
      " 40  rr                 89517 non-null  float64\n",
      " 41  spo2               89517 non-null  float64\n",
      " 42  vt                 89512 non-null  float64\n",
      " 43  chart_time_y       89532 non-null  float64\n",
      " 44  alp                89455 non-null  float64\n",
      " 45  alt                89465 non-null  float64\n",
      " 46  ast                89465 non-null  float64\n",
      " 47  chloride           89471 non-null  float64\n",
      " 48  creatinine         89467 non-null  float64\n",
      " 49  glucose            89527 non-null  float64\n",
      " 50  hb                 89488 non-null  float64\n",
      " 51  hco3               89520 non-null  float64\n",
      " 52  lymphocyte         89460 non-null  float64\n",
      " 53  platelet           89461 non-null  float64\n",
      " 54  potassium          89523 non-null  float64\n",
      " 55  sodium             89522 non-null  float64\n",
      " 56  total_bilirubin    89454 non-null  float64\n",
      " 57  wbc                89465 non-null  float64\n",
      " 58  LOS                91862 non-null  float64\n",
      " 59  is_outlier         91862 non-null  int64  \n",
      " 60  prolonged_LOS      91862 non-null  int64  \n",
      " 61  icu_visit          91862 non-null  int64  \n",
      " 62  or_duration        91852 non-null  float64\n",
      " 63  anesth_duration    91612 non-null  float64\n",
      "dtypes: float64(43), int64(13), object(8)\n",
      "memory usage: 45.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Data Import\n",
    "#\n",
    "#########################\n",
    "df = pd.read_csv('../../_data/operations_imputed_CLEAN.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91862 entries, 0 to 102290\n",
      "Data columns (total 37 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              91862 non-null  int64  \n",
      " 1   sex              91862 non-null  object \n",
      " 2   weight           90910 non-null  float64\n",
      " 3   height           91326 non-null  float64\n",
      " 4   asa              89532 non-null  float64\n",
      " 5   department       91862 non-null  object \n",
      " 6   antype           91862 non-null  object \n",
      " 7   category_id      91862 non-null  object \n",
      " 8   art_mbp          89504 non-null  float64\n",
      " 9   art_sbp          89497 non-null  float64\n",
      " 10  bt               89479 non-null  float64\n",
      " 11  cvp              89248 non-null  float64\n",
      " 12  hr               89515 non-null  float64\n",
      " 13  pip              89519 non-null  float64\n",
      " 14  pmean            89508 non-null  float64\n",
      " 15  rr               89517 non-null  float64\n",
      " 16  spo2             89517 non-null  float64\n",
      " 17  vt               89512 non-null  float64\n",
      " 18  chart_time_y     89532 non-null  float64\n",
      " 19  alp              89455 non-null  float64\n",
      " 20  alt              89465 non-null  float64\n",
      " 21  ast              89465 non-null  float64\n",
      " 22  chloride         89471 non-null  float64\n",
      " 23  creatinine       89467 non-null  float64\n",
      " 24  glucose          89527 non-null  float64\n",
      " 25  hb               89488 non-null  float64\n",
      " 26  hco3             89520 non-null  float64\n",
      " 27  lymphocyte       89460 non-null  float64\n",
      " 28  platelet         89461 non-null  float64\n",
      " 29  potassium        89523 non-null  float64\n",
      " 30  sodium           89522 non-null  float64\n",
      " 31  total_bilirubin  89454 non-null  float64\n",
      " 32  wbc              89465 non-null  float64\n",
      " 33  prolonged_LOS    91862 non-null  int64  \n",
      " 34  icu_visit        91862 non-null  int64  \n",
      " 35  or_duration      91852 non-null  float64\n",
      " 36  anesth_duration  91612 non-null  float64\n",
      "dtypes: float64(30), int64(3), object(4)\n",
      "memory usage: 26.6+ MB\n",
      "        age sex  weight  height  asa department     antype category_id  \\\n",
      "0        30   F    48.0   153.0  NaN         OT    General         09B   \n",
      "2        35   F    54.0     NaN  NaN         OG  Neuraxial         10D   \n",
      "3        50   F    66.0   157.0  2.0         OS    General         0NQ   \n",
      "4        60   F    62.0   154.0  1.0         GS    General         0GT   \n",
      "5        35   F    50.0   160.0  1.0         OS  Neuraxial         09B   \n",
      "...     ...  ..     ...     ...  ...        ...        ...         ...   \n",
      "102286   50   F    58.0   162.0  2.0         GS    General         0DN   \n",
      "102287   70   F    53.0   162.0  2.0         GS    General         0HB   \n",
      "102288   65   F    51.0   152.0  2.0         GS    General         0HB   \n",
      "102289   85   M    74.0   171.0  4.0         GS    General         0DB   \n",
      "102290   70   M    78.0   182.0  2.0         GS    General         0FT   \n",
      "\n",
      "           art_mbp     art_sbp  ...  lymphocyte    platelet  potassium  \\\n",
      "0              NaN         NaN  ...         NaN         NaN        NaN   \n",
      "2              NaN         NaN  ...         NaN         NaN        NaN   \n",
      "3       100.826720  137.244265  ...   20.414394  223.140988   3.768724   \n",
      "4       100.773779  138.601562  ...   23.938716  217.282759   3.846584   \n",
      "5        98.084871  131.646617  ...   13.300000  124.000000   3.900000   \n",
      "...            ...         ...  ...         ...         ...        ...   \n",
      "102286  100.826720  137.244265  ...   20.414394  223.140988   3.800000   \n",
      "102287   99.036609  142.337732  ...   21.154115  212.690065   3.700000   \n",
      "102288   97.106931  138.279011  ...   21.422042  212.006881   3.800000   \n",
      "102289   92.000000  152.000000  ...   19.733333  218.800000   3.900000   \n",
      "102290   99.157658  142.864730  ...   19.047368  200.625000   4.056197   \n",
      "\n",
      "            sodium  total_bilirubin       wbc  prolonged_LOS  icu_visit  \\\n",
      "0              NaN              NaN       NaN              0          0   \n",
      "2              NaN              NaN       NaN              1          0   \n",
      "3       139.116926         0.851504  8.957105              1          0   \n",
      "4       140.033084         0.744921  8.200501              1          0   \n",
      "5       138.000000         0.600000  6.310000              0          0   \n",
      "...            ...              ...       ...            ...        ...   \n",
      "102286  134.000000         0.851504  8.957105              0          0   \n",
      "102287  142.000000         0.760224  8.535719              1          0   \n",
      "102288  143.000000         0.780793  8.557983              1          0   \n",
      "102289  137.000000         1.800000  9.932500              1          1   \n",
      "102290  138.322951         1.037102  9.585853              0          0   \n",
      "\n",
      "        or_duration  anesth_duration  \n",
      "0              90.0            115.0  \n",
      "2             100.0            125.0  \n",
      "3              45.0             70.0  \n",
      "4              70.0             90.0  \n",
      "5             115.0            150.0  \n",
      "...             ...              ...  \n",
      "102286        160.0            180.0  \n",
      "102287         60.0             75.0  \n",
      "102288         55.0             75.0  \n",
      "102289        130.0            170.0  \n",
      "102290         55.0             70.0  \n",
      "\n",
      "[91862 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# Drop Target Column, NaN columns and excluded Features\n",
    "#\n",
    "#########################\n",
    "# \n",
    "## Drop cols with many NaN\n",
    "\n",
    "columns_w_NaN = ['art_dbp']  # Define as a list\n",
    "\n",
    "## Drop Excluded Features\n",
    "cols_to_drop = columns_w_NaN + ['op_id', 'subject_id', 'hadm_id', 'opdate', 'is_outlier', 'category_desc', 'desc_short', 'subject_id_y', 'inhosp_death_time', 'orin_time', 'orout_time', 'opstart_time', 'opend_time', 'admission_time', 'discharge_time', 'anstart_time', 'anend_time', 'cpbon_time', 'cpboff_time', 'icuin_time', 'icuout_time', 'icd10_pcs', 'chart_time_x', 'race', 'emop']  # Include 'art_dbp' directly\n",
    "\n",
    "\n",
    "# Check if the columns exist in the DataFrame before dropping them\n",
    "missing_columns = [col for col in cols_to_drop if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(\"Columns not found in DataFrame:\", missing_columns)\n",
    "\n",
    "df = df.drop(columns=cols_to_drop, axis=1)\n",
    "\n",
    "# Drop Targets\n",
    "y_target_reg = 'LOS'\n",
    "\n",
    "# Confirm\n",
    "x_df = df.drop([y_target_reg], axis=1)\n",
    "\n",
    "# Check the info of the resulting DataFrame\n",
    "x_df.info()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87844 entries, 3 to 102290\n",
      "Data columns (total 37 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              87844 non-null  int64  \n",
      " 1   sex              87844 non-null  object \n",
      " 2   weight           87844 non-null  float64\n",
      " 3   height           87844 non-null  float64\n",
      " 4   asa              87844 non-null  float64\n",
      " 5   department       87844 non-null  object \n",
      " 6   antype           87844 non-null  object \n",
      " 7   category_id      87844 non-null  object \n",
      " 8   art_mbp          87844 non-null  float64\n",
      " 9   art_sbp          87844 non-null  float64\n",
      " 10  bt               87844 non-null  float64\n",
      " 11  cvp              87844 non-null  float64\n",
      " 12  hr               87844 non-null  float64\n",
      " 13  pip              87844 non-null  float64\n",
      " 14  pmean            87844 non-null  float64\n",
      " 15  rr               87844 non-null  float64\n",
      " 16  spo2             87844 non-null  float64\n",
      " 17  vt               87844 non-null  float64\n",
      " 18  chart_time_y     87844 non-null  float64\n",
      " 19  alp              87844 non-null  float64\n",
      " 20  alt              87844 non-null  float64\n",
      " 21  ast              87844 non-null  float64\n",
      " 22  chloride         87844 non-null  float64\n",
      " 23  creatinine       87844 non-null  float64\n",
      " 24  glucose          87844 non-null  float64\n",
      " 25  hb               87844 non-null  float64\n",
      " 26  hco3             87844 non-null  float64\n",
      " 27  lymphocyte       87844 non-null  float64\n",
      " 28  platelet         87844 non-null  float64\n",
      " 29  potassium        87844 non-null  float64\n",
      " 30  sodium           87844 non-null  float64\n",
      " 31  total_bilirubin  87844 non-null  float64\n",
      " 32  wbc              87844 non-null  float64\n",
      " 33  prolonged_LOS    87844 non-null  int64  \n",
      " 34  icu_visit        87844 non-null  int64  \n",
      " 35  or_duration      87844 non-null  float64\n",
      " 36  anesth_duration  87844 non-null  float64\n",
      "dtypes: float64(30), int64(3), object(4)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "x_df = x_df.dropna()\n",
    "x_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'department', 'antype', 'category_id', 'asa']\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#\n",
    "# One-Hot encode categorical Features\n",
    "#\n",
    "#########################\n",
    "\n",
    "# Filter columns with dtype 'object'\n",
    "object_columns = x_df.select_dtypes(include='object').columns.tolist()\n",
    "numeric_columns = ['asa']\n",
    "encode_columns = object_columns +numeric_columns\n",
    "\n",
    "print(encode_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\anaconda3\\envs\\Lighthouse_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category_id_0HX', 'category_id_0DB', 'category_id_0SG', 'category_id_0H8', 'category_id_0DH', 'category_id_09R', 'category_id_0SP', 'category_id_00P', 'category_id_0RB', 'antype_Neuraxial', 'category_id_0N9', 'department_UR', 'category_id_0W1', 'category_id_0J8', 'asa_6.0', 'category_id_0NP', 'category_id_03B', 'category_id_02J', 'category_id_0QS', 'category_id_08D', 'department_PS', 'category_id_0QH', 'category_id_10D', 'category_id_099', 'category_id_0RP', 'sex_M', 'department_GS', 'category_id_0DT', 'category_id_0D1', 'category_id_0Q9', 'department_OT', 'category_id_03C', 'category_id_0DV', 'category_id_0VC', 'category_id_021', 'category_id_0FY', 'category_id_0BN', 'category_id_08R', 'category_id_00X', 'category_id_0HR', 'category_id_0SR', 'category_id_04C', 'department_CTS', 'category_id_0GT', 'category_id_0H9', 'category_id_0RW', 'category_id_0FB', 'category_id_0CR', 'antype_Regional', 'department_RAD', 'category_id_0MB', 'category_id_0WJ', 'category_id_0RH', 'category_id_0SB', 'category_id_0BJ', 'antype_MAC', 'category_id_0BB', 'category_id_09P', 'asa_4.0', 'category_id_05H', 'asa_3.0', 'category_id_0BQ', 'category_id_0PP', 'category_id_02H', 'category_id_02S', 'asa_5.0', 'category_id_031', 'department_PED', 'category_id_047', 'category_id_0YH', 'category_id_0HQ', 'category_id_00B', 'category_id_0DJ', 'category_id_02C', 'category_id_0Y6', 'category_id_0BW', 'category_id_0SS', 'category_id_0VB', 'category_id_02Q', 'department_DM', 'category_id_0NQ', 'category_id_0DN', 'category_id_0CJ', 'category_id_0NB', 'category_id_02Y', 'category_id_0W3', 'category_id_0F9', 'category_id_0HB', 'department_OG', 'category_id_0BY', 'category_id_03L', 'category_id_0BT', 'department_IM', 'category_id_0M9', 'category_id_027', 'category_id_0TB', 'category_id_0TT', 'category_id_02L', 'category_id_009', 'category_id_02B', 'category_id_09B', 'department_OL', 'category_id_0BD', 'department_OS', 'category_id_04B', 'category_id_0W2', 'category_id_0WB', 'category_id_0UT', 'category_id_041', 'category_id_0GQ', 'category_id_0PB', 'category_id_02R', 'category_id_0R9', 'category_id_0W9', 'category_id_09Q', 'category_id_0B1', 'category_id_0PS', 'category_id_04R', 'category_id_0HD', 'category_id_02V', 'category_id_0UV', 'category_id_089', 'category_id_00J', 'category_id_0FQ', 'department_NS', 'category_id_0JB', 'category_id_07L', 'department_EM', 'category_id_0RG', 'category_id_0SW', 'category_id_0DQ', 'category_id_0KQ', 'asa_2.0', 'category_id_00Q', 'category_id_0QQ', 'category_id_0FT', 'category_id_0PH']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>art_mbp</th>\n",
       "      <th>art_sbp</th>\n",
       "      <th>bt</th>\n",
       "      <th>cvp</th>\n",
       "      <th>hr</th>\n",
       "      <th>pip</th>\n",
       "      <th>pmean</th>\n",
       "      <th>...</th>\n",
       "      <th>category_id_0WB</th>\n",
       "      <th>category_id_0WJ</th>\n",
       "      <th>category_id_0Y6</th>\n",
       "      <th>category_id_0YH</th>\n",
       "      <th>category_id_10D</th>\n",
       "      <th>asa_2.0</th>\n",
       "      <th>asa_3.0</th>\n",
       "      <th>asa_4.0</th>\n",
       "      <th>asa_5.0</th>\n",
       "      <th>asa_6.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>100.826720</td>\n",
       "      <td>137.244265</td>\n",
       "      <td>29.656043</td>\n",
       "      <td>2.457447</td>\n",
       "      <td>78.792763</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.893834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>138.601562</td>\n",
       "      <td>28.462637</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.485501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>98.084871</td>\n",
       "      <td>131.646617</td>\n",
       "      <td>29.201952</td>\n",
       "      <td>7.653846</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.546358</td>\n",
       "      <td>3.803659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.702290</td>\n",
       "      <td>140.826772</td>\n",
       "      <td>35.800000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>12.820417</td>\n",
       "      <td>4.017967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>100.773779</td>\n",
       "      <td>138.601562</td>\n",
       "      <td>28.462637</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.485501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87814</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87818</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87822</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87830</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87843</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100905 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  weight  height     art_mbp     art_sbp         bt       cvp  \\\n",
       "3      50.0    66.0   157.0  100.826720  137.244265  29.656043  2.457447   \n",
       "4      60.0    62.0   154.0  100.773779  138.601562  28.462637  0.603448   \n",
       "5      35.0    50.0   160.0   98.084871  131.646617  29.201952  7.653846   \n",
       "6      20.0    62.0   179.0   92.702290  140.826772  35.800000  0.272727   \n",
       "7      60.0    52.0   152.0  100.773779  138.601562  28.462637  0.603448   \n",
       "...     ...     ...     ...         ...         ...        ...       ...   \n",
       "87814   NaN     NaN     NaN         NaN         NaN        NaN       NaN   \n",
       "87818   NaN     NaN     NaN         NaN         NaN        NaN       NaN   \n",
       "87822   NaN     NaN     NaN         NaN         NaN        NaN       NaN   \n",
       "87830   NaN     NaN     NaN         NaN         NaN        NaN       NaN   \n",
       "87843   NaN     NaN     NaN         NaN         NaN        NaN       NaN   \n",
       "\n",
       "              hr        pip     pmean  ...  category_id_0WB  category_id_0WJ  \\\n",
       "3      78.792763   4.000000  4.893834  ...              0.0              0.0   \n",
       "4      62.000000   5.000000  4.485501  ...              0.0              0.0   \n",
       "5      82.000000  13.546358  3.803659  ...              0.0              0.0   \n",
       "6      94.000000  12.820417  4.017967  ...              0.0              0.0   \n",
       "7      68.000000   4.000000  4.485501  ...              0.0              0.0   \n",
       "...          ...        ...       ...  ...              ...              ...   \n",
       "87814        NaN        NaN       NaN  ...              0.0              0.0   \n",
       "87818        NaN        NaN       NaN  ...              0.0              0.0   \n",
       "87822        NaN        NaN       NaN  ...              0.0              0.0   \n",
       "87830        NaN        NaN       NaN  ...              0.0              0.0   \n",
       "87843        NaN        NaN       NaN  ...              0.0              0.0   \n",
       "\n",
       "       category_id_0Y6  category_id_0YH  category_id_10D  asa_2.0  asa_3.0  \\\n",
       "3                  0.0              0.0              0.0      0.0      0.0   \n",
       "4                  0.0              0.0              0.0      0.0      0.0   \n",
       "5                  0.0              0.0              0.0      1.0      0.0   \n",
       "6                  0.0              0.0              0.0      1.0      0.0   \n",
       "7                  0.0              0.0              0.0      0.0      0.0   \n",
       "...                ...              ...              ...      ...      ...   \n",
       "87814              0.0              0.0              0.0      0.0      1.0   \n",
       "87818              0.0              0.0              0.0      0.0      1.0   \n",
       "87822              0.0              0.0              0.0      1.0      0.0   \n",
       "87830              0.0              0.0              0.0      1.0      0.0   \n",
       "87843              0.0              0.0              0.0      1.0      0.0   \n",
       "\n",
       "       asa_4.0  asa_5.0  asa_6.0  \n",
       "3          0.0      0.0      0.0  \n",
       "4          0.0      0.0      0.0  \n",
       "5          0.0      0.0      0.0  \n",
       "6          0.0      0.0      0.0  \n",
       "7          0.0      0.0      0.0  \n",
       "...        ...      ...      ...  \n",
       "87814      0.0      0.0      0.0  \n",
       "87818      0.0      0.0      0.0  \n",
       "87822      0.0      0.0      0.0  \n",
       "87830      0.0      0.0      0.0  \n",
       "87843      0.0      0.0      0.0  \n",
       "\n",
       "[100905 rows x 169 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## use OneHot instead of get_dummies\n",
    "        \n",
    "def encode_cat_vars(x, columns_to_encode):\n",
    "    original_cols = set(x.columns)\n",
    "    \n",
    "    # Extract the object columns\n",
    "    \n",
    "    # object_columns = [col for col in x.columns if col in columns_to_encode]\n",
    "    \n",
    "    # Initialize the OneHotEncoder\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    \n",
    "    # Fit and transform the encoder on the object columns\n",
    "    encoded_data = encoder.fit_transform(x[columns_to_encode])\n",
    "    \n",
    "    # Create a DataFrame from the encoded data with appropriate column names\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(columns_to_encode))\n",
    "    \n",
    "    # Drop the original object columns\n",
    "    x = x.drop(columns_to_encode, axis=1)\n",
    "    \n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    x = pd.concat([x, encoded_df], axis=1)\n",
    "    \n",
    "    # Get the newly added columns\n",
    "    dummy_cols = list(set(x.columns) - original_cols)\n",
    "    \n",
    "    return x, dummy_cols\n",
    "\n",
    "# Dummy variable creation is done before splitting the data, so all the different categories are covered\n",
    "# Create dummy variables\n",
    "df_encoded, dummy_columns = encode_cat_vars(x_df, encode_columns)\n",
    "\n",
    "#confirm:\n",
    "# df_encoded = df_encoded.dropna(subset=['LOS'])\n",
    "print(dummy_columns)\n",
    "df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded=df_encoded.dropna()\n",
    "\n",
    "df_encoded.to_csv('../../_data/1hot_encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With current categories- there are 164 features after 1-ht. This may be a problem. \n",
    "Need to remember that each model will be trained on the category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "#########################\n",
    "#\n",
    "# Principal Component Analysis - PCA - Demographics\n",
    "#\n",
    "#########################\n",
    "# \n",
    "target_column = y_target_cat  # Replace with the y_regression if want to change model to regression. \n",
    "object_columns = [col for col in df_encoded.columns if col != target_column]\n",
    "\n",
    "# Initialize the HistGradientBoostingClassifier for feature selection\n",
    "gbdt = HistGradientBoostingClassifier(random_state=0)\n",
    "gbdt.fit(df_encoded[object_columns], df_encoded[target_column])\n",
    "\n",
    "# Get feature importances from the trained GBDT model\n",
    "feature_importances = gbdt.feature_importances_\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "# Select the top N most important features (you can adjust N as needed)\n",
    "num_selected_features = 3  # revise thise following our skree plot (below)\n",
    "selected_feature_indices = sorted_indices[:num_selected_features]\n",
    "\n",
    "# Extract the selected features from your DataFrame\n",
    "selected_features = df_encoded.iloc[:, selected_feature_indices]\n",
    "\n",
    "# Now, you can perform PCA on the selected features\n",
    "scaled_data = selected_features.values  # Convert to NumPy array\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Troubleshoot any NaN values in PCA\n",
    "#\n",
    "#########################\n",
    "\n",
    "# Check for NaN values in the 'y' column\n",
    "nan_indices = df_encoded[df_encoded.columns].isna()\n",
    "print(nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "#\n",
    "# Draw a scree plot and a PCA plot\n",
    "#\n",
    "#########################\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#The following code constructs the Scree plot\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n",
    " \n",
    "#the following code makes a fancy looking plot using PC1 and PC2\n",
    "pca_df = pd.DataFrame(pca_data, index=[*wt, *ko], columns=labels)\n",
    " \n",
    "plt.scatter(pca_df.PC1, pca_df.PC2)\n",
    "plt.title('My PCA Graph')\n",
    "plt.xlabel('PC1 - {0}%'.format(per_var[0]))\n",
    "plt.ylabel('PC2 - {0}%'.format(per_var[1]))\n",
    " \n",
    "for sample in pca_df.index:\n",
    "    plt.annotate(sample, (pca_df.PC1.loc[sample], pca_df.PC2.loc[sample]))\n",
    " \n",
    "plt.show()\n",
    " \n",
    "#########################\n",
    "#\n",
    "# Determine which genes had the biggest influence on PC1\n",
    "#\n",
    "#########################\n",
    " \n",
    "## get the name of the top 10 measurements (genes) that contribute\n",
    "## most to pc1.\n",
    "## first, get the loading scores\n",
    "loading_scores = pd.Series(pca.components_[0], index=genes)\n",
    "## now sort the loading scores based on their magnitude\n",
    "sorted_loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
    " \n",
    "# get the names of the top 10 genes\n",
    "top_10_genes = sorted_loading_scores[0:10].index.values\n",
    " \n",
    "## print the gene names and their scores (and +/- sign)\n",
    "print(loading_scores[top_10_genes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
